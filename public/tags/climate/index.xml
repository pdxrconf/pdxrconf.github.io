<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Climate on rOpenSci - open tools for open science</title>
    <link>https://ropensci.org/tags/climate/</link>
    <description>Recent content in Climate on rOpenSci - open tools for open science</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 01 Mar 2017 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://ropensci.org/tags/climate/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>ccafs - client for CCAFS General Circulation Models data</title>
      <link>https://ropensci.org/technotes/2017/03/01/ccafs-release/</link>
      <pubDate>Wed, 01 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/technotes/2017/03/01/ccafs-release/</guid>
      <description>
        
        

&lt;p&gt;I&amp;rsquo;ve recently released the new package &lt;a href=&#34;https://github.com/ropensci/ccafs&#34;&gt;ccafs&lt;/a&gt;, which provides access
to data from Climate Change, Agriculture and Food Security
(CCAFS; &lt;a href=&#34;http://ccafs-climate.org/&#34;&gt;http://ccafs-climate.org/&lt;/a&gt;) General Circulation Models (GCM) data.
GCM&amp;rsquo;s are a particular type of climate model, used for weather forecasting,
and climate change forecasting - read more at
&lt;a href=&#34;https://en.wikipedia.org/wiki/General_circulation_model&#34;&gt;https://en.wikipedia.org/wiki/General_circulation_model&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ccafs&lt;/code&gt; falls in the data client camp - its focus is on getting users
data - many &lt;a href=&#34;https://ropensci.org/packages/#data_access&#34;&gt;rOpenSci packages&lt;/a&gt;
fall into this area. These kinds of packages are important so that
scientists don&amp;rsquo;t have to recreate the wheel themselves every time, but
instead use one client that everyone else uses.&lt;/p&gt;

&lt;p&gt;CCAFS GCM data files are &lt;code&gt;.zip&lt;/code&gt; files with a bunch of files inside. The
individual files are in ARC ASCII format (&lt;a href=&#34;https://en.wikipedia.org/wiki/Esri_grid#ASCII&#34;&gt;https://en.wikipedia.org/wiki/Esri_grid#ASCII&lt;/a&gt;) -
a plain text data format, but still require painful manipulation/wrangling to
get into an easily consumable format. The files have a &lt;code&gt;.asc&lt;/code&gt; file extension.&lt;/p&gt;

&lt;p&gt;For each &lt;code&gt;.asc&lt;/code&gt; file, the first 6 lines of each file indicate the reference of
the grid (number of columns and rows, corner coordinates, cellsize, and missing
data value), followed by the actual data values, delimited with single
space characters.&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s a related binary format - but its proprietary, so nevermind.&lt;/p&gt;

&lt;p&gt;The workflow with &lt;code&gt;ccafs&lt;/code&gt; for most users will likely be as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Search for data they want: &lt;code&gt;cc_search()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fetch/download data: &lt;code&gt;cc_data_fetch()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Reaad data: &lt;code&gt;cc_data_read()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I&amp;rsquo;ll dive into more details below.&lt;/p&gt;

&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;

&lt;p&gt;First, install the package.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;ccafs&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then load &lt;code&gt;ccafs&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;ccafs&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;search-for-data&#34;&gt;Search for data&lt;/h2&gt;

&lt;p&gt;Searching CCAF&amp;rsquo;s data holdings is not as easy as it could be as they don&amp;rsquo;t
provide any programmatic way to do so. However, we provide a way to search
using their web interface from R.&lt;/p&gt;

&lt;p&gt;You can search by the numbers representing each possible value for
each parameter. See the &lt;code&gt;?&#39;ccafs-search&#39;&lt;/code&gt; for help on what the numbers
refer to.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;(result1 &amp;lt;- cc_search(file_set = 4, scenario = 6, model = 2, extent = &amp;quot;global&amp;quot;,
  format = &amp;quot;ascii&amp;quot;, period = 5, variable = 2, resolution = 3))
#&amp;gt; [1] &amp;quot;http://gisweb.ciat.cgiar.org/ccafs_climate/files/data/ipcc_4ar_ciat/sres_b1/2040s/bccr_bcm2_0/5min/bccr_bcm2_0_sres_b1_2040s_prec_5min_no_tile_asc.zip&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Alternatively, you can use the helper list &lt;code&gt;cc_params&lt;/code&gt; where you can reference
options by name; the downside is that this leads to very verbose code.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;(result2 &amp;lt;- cc_search(file_set = cc_params$file_set$`Delta method IPCC AR4`,
                  scenario = cc_params$scenario$`SRES B1`,
                  model = cc_params$model$bccr_bcm2_0,
                  extent = cc_params$extent$global,
                  format = cc_params$format$ascii,
                  period = cc_params$period$`2040s`,
                  variable = cc_params$variable$Precipitation,
                  resolution = cc_params$resolution$`5 minutes`))
#&amp;gt; [1] &amp;quot;http://gisweb.ciat.cgiar.org/ccafs_climate/files/data/ipcc_4ar_ciat/sres_b1/2040s/bccr_bcm2_0/5min/bccr_bcm2_0_sres_b1_2040s_prec_5min_no_tile_asc.zip&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you already know what you want in terms of file paths, you can query
Amazon S3 directly with &lt;code&gt;cc_list_keys()&lt;/code&gt; (the data file come from Amazon S3):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cc_list_keys(max = 3)
#&amp;gt; # A tibble: 3 × 5
#&amp;gt;                                              Key             LastModified
#&amp;gt;                                            &amp;lt;chr&amp;gt;                    &amp;lt;chr&amp;gt;
#&amp;gt; 1                                         ccafs/ 2014-02-28T15:15:45.000Z
#&amp;gt; 2 ccafs/2014-05-24-01-19-33-3A0DFF1F86F3E7F7.txt 2014-07-01T02:15:51.000Z
#&amp;gt; 3                                 ccafs/amzn.csv 2014-02-28T15:21:32.000Z
#&amp;gt; # ... with 3 more variables: ETag &amp;lt;chr&amp;gt;, Size &amp;lt;chr&amp;gt;, StorageClass &amp;lt;chr&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When using &lt;code&gt;cc_list_keys()&lt;/code&gt;, you&amp;rsquo;ll get not just &lt;code&gt;.zip&lt;/code&gt; files that can be
downloaded, but also directories. So beware that if you&amp;rsquo;re going after grabbing
&amp;ldquo;keys&amp;rdquo; for files that can be downloaded, you&amp;rsquo;re looking for &lt;code&gt;.zip&lt;/code&gt; files.&lt;/p&gt;

&lt;h2 id=&#34;fetch-and-read-data&#34;&gt;Fetch and read data&lt;/h2&gt;

&lt;p&gt;Once you get links from &lt;code&gt;cc_search()&lt;/code&gt; or &amp;ldquo;keys&amp;rdquo; from &lt;code&gt;cc_list_keys()&lt;/code&gt;, you
can pass either to &lt;code&gt;cc_data_fetch()&lt;/code&gt; - which normalizes the input - so it
doesn&amp;rsquo;t matter whether you pass in e.g.,&lt;/p&gt;

&lt;p&gt;&lt;code&gt;http://gisweb.ciat.cgiar.org/ccafs_climate/files/data/ipcc_4ar_ciat/&lt;/code&gt;
&lt;code&gt;sres_b1/2040s/bccr_bcm2_0/5min/bccr_bcm2_0_sres_b1_2040s_prec_5min_no_tile_asc.zip&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ccafs_climate/files/data/ipcc_4ar_ciat/sres_b1/2040s/bccr_bcm2_0/5min/&lt;/code&gt;
&lt;code&gt;bccr_bcm2_0_sres_b1_2040s_prec_5min_no_tile_asc.zip&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s download data with &lt;code&gt;cc_data_fetch()&lt;/code&gt; using the result we got above
using &lt;code&gt;cc_search()&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;xx &amp;lt;- cc_data_fetch(result2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we can read data with &lt;code&gt;cc_data_read()&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;(dat &amp;lt;- cc_data_read(xx))
#&amp;gt; class       : RasterStack
#&amp;gt; dimensions  : 1800, 4320, 7776000, 12  (nrow, ncol, ncell, nlayers)
#&amp;gt; resolution  : 0.08333333, 0.08333333  (x, y)
#&amp;gt; extent      : -180, 180, -60, 90  (xmin, xmax, ymin, ymax)
#&amp;gt; coord. ref. : NA
#&amp;gt; names       :      prec_1,     prec_10,     prec_11,     prec_12,      prec_2,      prec_3,      prec_4,      prec_5,      prec_6,      prec_7,      prec_8,      prec_9
#&amp;gt; min values  : -2147483648, -2147483648, -2147483648, -2147483648, -2147483648, -2147483648, -2147483648, -2147483648, -2147483648, -2147483648, -2147483648, -2147483648
#&amp;gt; max values  :  2147483647,  2147483647,  2147483647,  2147483647,  2147483647,  2147483647,  2147483647,  2147483647,  2147483647,  2147483647,  2147483647,  2147483647
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which gives a &lt;code&gt;raster&lt;/code&gt; class object, which you are likely familiar with - which
opens up all the tools that deal with &lt;code&gt;raster&lt;/code&gt; class objects, yay!&lt;/p&gt;

&lt;p&gt;You can easily plot the data with the &lt;code&gt;plot&lt;/code&gt; method from the  &lt;code&gt;raster&lt;/code&gt; package.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;raster&amp;quot;)
plot(dat)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2017-03-01-ccafs-release/unnamed-chunk-9-1.png&#34; alt=&#34;plot&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;caching&#34;&gt;Caching&lt;/h2&gt;

&lt;p&gt;For a better user experience, we cache files for you. That means
when we download data, we put the files in a known location. When a
user tries to download the same data again, we look to see if it&amp;rsquo;s already
been downloaded, and use the cached version - if we don&amp;rsquo;t have it
already, we download it.&lt;/p&gt;

&lt;p&gt;Of course, CCAFS may change their files, so you may not want the cached
version, but the new version from them. We provide tools to inspect your
cached files, and delete them.&lt;/p&gt;

&lt;p&gt;List your cached files:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cc_cache_list()
#&amp;gt;   [1] &amp;quot;/Users/sacmac/Library/Caches/ccafs/bcc_csm1_1_m_rcp2_6_2030s_bio_10min_r1i1p1_no_tile_asc&amp;quot;
#&amp;gt;   [2] &amp;quot;/Users/sacmac/Library/Caches/ccafs/bcc_csm1_1_m_rcp2_6_2030s_bio_10min_r1i1p1_no_tile_asc.zip&amp;quot;
#&amp;gt;   [3] &amp;quot;/Users/sacmac/Library/Caches/ccafs/bcc_csm1_1_m_rcp2_6_2030s_bio_10min_r1i1p1_no_tile_asc/bio_1.asc&amp;quot;
#&amp;gt;   [4] &amp;quot;/Users/sacmac/Library/Caches/ccafs/bcc_csm1_1_m_rcp2_6_2030s_bio_10min_r1i1p1_no_tile_asc/bio_10.asc&amp;quot;
#&amp;gt;   [5] &amp;quot;/Users/sacmac/Library/Caches/ccafs/bcc_csm1_1_m_rcp2_6_2030s_bio_10min_r1i1p1_no_tile_asc/bio_11.asc&amp;quot;
#&amp;gt;   [6] &amp;quot;/Users/sacmac/Library/Caches/ccafs/bcc_csm1_1_m_rcp2_6_2030s_bio_10min_r1i1p1_no_tile_asc/bio_12.asc&amp;quot;
#&amp;gt;   [7] &amp;quot;/Users/sacmac/Library/Caches/ccafs/bcc_csm1_1_m_rcp2_6_2030s_bio_10min_r1i1p1_no_tile_asc/bio_13.asc&amp;quot;
#&amp;gt;   [8] &amp;quot;/Users/sacmac/Library/Caches/ccafs/bcc_csm1_1_m_rcp2_6_2030s_bio_10min_r1i1p1_no_tile_asc/bio_14.asc&amp;quot;
#&amp;gt;   [9] &amp;quot;/Users/sacmac/Library/Caches/ccafs/bcc_csm1_1_m_rcp2_6_2030s_bio_10min_r1i1p1_no_tile_asc/bio_15.asc&amp;quot;
#&amp;gt;  [10] &amp;quot;/Users/sacmac/Library/Caches/ccafs/bcc_csm1_1_m_rcp2_6_2030s_bio_10min_r1i1p1_no_tile_asc/bio_16.asc&amp;quot;
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Get details on all files or a specific file:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# cc_cache_details() # details for all files
cc_cache_details(cc_cache_list()[1])
#&amp;gt; &amp;lt;ccafs cached files&amp;gt;
#&amp;gt;   directory: /Users/sacmac/Library/Caches/ccafs
#&amp;gt;
#&amp;gt;   file: /bcc_csm1_1_m_rcp2_6_2030s_bio_10min_r1i1p1_no_tile_asc
#&amp;gt;   size: 0.001 mb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Be careful with &lt;code&gt;cc_cache_delete_all()&lt;/code&gt; as you will delete all your cached
files.&lt;/p&gt;

&lt;h2 id=&#34;ccafs-software-review&#34;&gt;ccafs software review&lt;/h2&gt;

&lt;p&gt;I want to touch briefly on the software review for this package. The reviews
for &lt;code&gt;ccafs&lt;/code&gt; were great, and I think the package was greatly improved via the
review process.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/mikoontz&#34;&gt;Michael Koontz&lt;/a&gt; and &lt;a href=&#34;https://github.com/manuramon&#34;&gt;Manuel Ramon&lt;/a&gt;
did reviews for &lt;code&gt;ccafs&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;One thing in particular that improved about &lt;code&gt;ccafs&lt;/code&gt; was the user interface -
that is, the programmatic interface. One feature about the interface was
adding the &lt;code&gt;cc_search()&lt;/code&gt; function. When I started developing &lt;code&gt;ccafs&lt;/code&gt;, I didn&amp;rsquo;t
see a way to programmatically search CCAFS data - other than the Amazon S3
data, which isn&amp;rsquo;t really search, but more like listing files in a directory -
so I just left it at that. During the reviews, reviewers wanted a clear workflow
for potential users - the package as submitted for review didn&amp;rsquo;t really have a
clear workflow; it was&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Know what you want already (&lt;code&gt;cc_list_keys&lt;/code&gt; helped get real paths at least)&lt;/li&gt;
&lt;li&gt;Download data&lt;/li&gt;
&lt;li&gt;Read data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Which is not ideal. There should be a discovery portion to the workflow. So
I decided to dig into possibly querying the CCAFS web portal itself. That panned
out, and the workflow we have now is much better:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Search for data with all the same variables you would on the CCAFS website&lt;/li&gt;
&lt;li&gt;Download data&lt;/li&gt;
&lt;li&gt;Read data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is much better!&lt;/p&gt;

&lt;p&gt;As always, reviews improved the documentation a lot by pointing out areas that
could use improvement - which all users will greatly benefit from.&lt;/p&gt;

&lt;p&gt;A new vignette (&lt;a href=&#34;https://cran.rstudio.com/web/packages/ccafs/vignettes/amazon_s3_keys.html&#34;&gt;https://cran.rstudio.com/web/packages/ccafs/vignettes/amazon_s3_keys.html&lt;/a&gt;)
was added in the review process to explain how to get a &amp;ldquo;key&amp;rdquo;, a URL for CCAFS data.&lt;/p&gt;

&lt;h2 id=&#34;to-do-and-feedback&#34;&gt;To Do and Feedback&lt;/h2&gt;

&lt;p&gt;There&amp;rsquo;s probably lots of improvements that can be made - I&amp;rsquo;m looking forward
to getting feedback from users on any bugs or feature requests. One immediate
thing is to &lt;a href=&#34;https://github.com/ropensci/ccafs/issues/22&#34;&gt;make the cache details more compact&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Parse NOAA Integrated Surface Data Files</title>
      <link>https://ropensci.org/technotes/2016/11/03/isdparser-release/</link>
      <pubDate>Thu, 03 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/technotes/2016/11/03/isdparser-release/</guid>
      <description>
        
        

&lt;p&gt;A new package &lt;a href=&#34;https://cran.rstudio.com/web/packages/isdparser&#34;&gt;isdparser&lt;/a&gt; is
on CRAN. &lt;code&gt;isdparser&lt;/code&gt; was in part liberated from &lt;a href=&#34;https://github.com/ropensci/rnoaa&#34;&gt;rnoaa&lt;/a&gt;,
then improved. We&amp;rsquo;ll use &lt;code&gt;isdparser&lt;/code&gt; in &lt;code&gt;rnoaa&lt;/code&gt; soon.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;isdparser&lt;/code&gt; does not download files for you from NOAA&amp;rsquo;s ftp servers. The
package focuses on parsing the files, which are variable length ASCII strings
stored line by line, where each line has some mandatory data, and any amount
of optional data.&lt;/p&gt;

&lt;p&gt;The data is great, and includes for example, wind speed and direction, temperature,
cloud data, sea level pressure, and more. Includes data from approximately 35,000
stations worldwide, though best coverage is in North America/Europe/Australia.
Data go all the way back to 1901, and are updated daily.&lt;/p&gt;

&lt;p&gt;However, &lt;a href=&#34;ftp://ftp.ncdc.noaa.gov/pub/data/noaa/&#34;&gt;the data&lt;/a&gt; is not fun to parse,
warranting an packge to deal with the parsing.&lt;/p&gt;

&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;isdparser&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If binaries aren&amp;rsquo;t available, try from source:
&lt;code&gt;install.packages(&amp;quot;isdparser&amp;quot;, type = &amp;quot;source&amp;quot;)&lt;/code&gt; or from GitHub:
&lt;code&gt;devtools::install_github(&amp;quot;ropenscilabs/isdparser&amp;quot;)&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(isdparser)
library(dplyr)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;parse-individual-lines&#34;&gt;Parse individual lines&lt;/h2&gt;

&lt;p&gt;If you want to parse individual lines, use &lt;code&gt;isd_parse_line()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;First, let&amp;rsquo;s get a ISD file. There&amp;rsquo;s a few that come with the package:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;path &amp;lt;- system.file(&#39;extdata/024130-99999-2016.gz&#39;, package = &amp;quot;isdparser&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Read in the file&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;lns &amp;lt;- readLines(path, encoding = &amp;quot;latin1&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Parse a line&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;isd_parse_line(lns[1])
#&amp;gt; # A tibble: 1 × 42
#&amp;gt;   total_chars usaf_station wban_station       date  time date_flag
#&amp;gt;         &amp;lt;dbl&amp;gt;        &amp;lt;chr&amp;gt;        &amp;lt;chr&amp;gt;     &amp;lt;date&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;
#&amp;gt; 1          54       024130        99999 2016-01-01  0000         4
#&amp;gt; # ... with 36 more variables: latitude &amp;lt;dbl&amp;gt;, longitude &amp;lt;dbl&amp;gt;,
#&amp;gt; #   type_code &amp;lt;chr&amp;gt;, elevation &amp;lt;dbl&amp;gt;, call_letter &amp;lt;chr&amp;gt;, quality &amp;lt;chr&amp;gt;,
#&amp;gt; #   wind_direction &amp;lt;dbl&amp;gt;, wind_direction_quality &amp;lt;chr&amp;gt;, wind_code &amp;lt;chr&amp;gt;,
#&amp;gt; #   wind_speed &amp;lt;dbl&amp;gt;, wind_speed_quality &amp;lt;chr&amp;gt;, ceiling_height &amp;lt;chr&amp;gt;,
#&amp;gt; #   ceiling_height_quality &amp;lt;chr&amp;gt;, ceiling_height_determination &amp;lt;chr&amp;gt;,
#&amp;gt; #   ceiling_height_cavok &amp;lt;chr&amp;gt;, visibility_distance &amp;lt;chr&amp;gt;,
#&amp;gt; #   visibility_distance_quality &amp;lt;chr&amp;gt;, visibility_code &amp;lt;chr&amp;gt;,
#&amp;gt; #   visibility_code_quality &amp;lt;chr&amp;gt;, temperature &amp;lt;dbl&amp;gt;,
#&amp;gt; #   temperature_quality &amp;lt;chr&amp;gt;, temperature_dewpoint &amp;lt;dbl&amp;gt;,
#&amp;gt; #   temperature_dewpoint_quality &amp;lt;chr&amp;gt;, air_pressure &amp;lt;dbl&amp;gt;,
#&amp;gt; #   air_pressure_quality &amp;lt;chr&amp;gt;,
#&amp;gt; #   AW1_present_weather_observation_identifier &amp;lt;chr&amp;gt;,
#&amp;gt; #   AW1_automated_atmospheric_condition_code &amp;lt;chr&amp;gt;,
#&amp;gt; #   AW1_quality_automated_atmospheric_condition_code &amp;lt;chr&amp;gt;,
#&amp;gt; #   N03_original_observation &amp;lt;chr&amp;gt;, N03_original_value_text &amp;lt;chr&amp;gt;,
#&amp;gt; #   N03_units_code &amp;lt;chr&amp;gt;, N03_parameter_code &amp;lt;chr&amp;gt;, REM_remarks &amp;lt;chr&amp;gt;,
#&amp;gt; #   REM_identifier &amp;lt;chr&amp;gt;, REM_length_quantity &amp;lt;chr&amp;gt;, REM_comment &amp;lt;chr&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By default you get a tibble back, but you can ask for a list in return instead.&lt;/p&gt;

&lt;p&gt;Parsing by line allows the user to decide how to apply parsing across lines,
whether it be &lt;code&gt;lapply&lt;/code&gt; style, or for loop, etc.&lt;/p&gt;

&lt;h2 id=&#34;parse-entire-files&#34;&gt;Parse entire files&lt;/h2&gt;

&lt;p&gt;You can also parse entire ISD files.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;isd_parse(path)
#&amp;gt; # A tibble: 2,601 × 42
#&amp;gt;    total_chars usaf_station wban_station       date  time date_flag
#&amp;gt;          &amp;lt;dbl&amp;gt;        &amp;lt;chr&amp;gt;        &amp;lt;chr&amp;gt;     &amp;lt;date&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;
#&amp;gt; 1           54       024130        99999 2016-01-01  0000         4
#&amp;gt; 2           54       024130        99999 2016-01-01  0100         4
#&amp;gt; 3           54       024130        99999 2016-01-01  0200         4
#&amp;gt; 4           54       024130        99999 2016-01-01  0300         4
#&amp;gt; 5           54       024130        99999 2016-01-01  0400         4
#&amp;gt; 6           39       024130        99999 2016-01-01  0500         4
#&amp;gt; 7           54       024130        99999 2016-01-01  0600         4
#&amp;gt; 8           39       024130        99999 2016-01-01  0700         4
#&amp;gt; 9           54       024130        99999 2016-01-01  0800         4
#&amp;gt; 10          54       024130        99999 2016-01-01  0900         4
#&amp;gt; # ... with 2,591 more rows, and 36 more variables: latitude &amp;lt;dbl&amp;gt;,
#&amp;gt; #   longitude &amp;lt;dbl&amp;gt;, type_code &amp;lt;chr&amp;gt;, elevation &amp;lt;dbl&amp;gt;, call_letter &amp;lt;chr&amp;gt;,
#&amp;gt; #   quality &amp;lt;chr&amp;gt;, wind_direction &amp;lt;dbl&amp;gt;, wind_direction_quality &amp;lt;chr&amp;gt;,
#&amp;gt; #   wind_code &amp;lt;chr&amp;gt;, wind_speed &amp;lt;dbl&amp;gt;, wind_speed_quality &amp;lt;chr&amp;gt;,
#&amp;gt; #   ceiling_height &amp;lt;chr&amp;gt;, ceiling_height_quality &amp;lt;chr&amp;gt;,
#&amp;gt; #   ceiling_height_determination &amp;lt;chr&amp;gt;, ceiling_height_cavok &amp;lt;chr&amp;gt;,
#&amp;gt; #   visibility_distance &amp;lt;chr&amp;gt;, visibility_distance_quality &amp;lt;chr&amp;gt;,
#&amp;gt; #   visibility_code &amp;lt;chr&amp;gt;, visibility_code_quality &amp;lt;chr&amp;gt;,
#&amp;gt; #   temperature &amp;lt;dbl&amp;gt;, temperature_quality &amp;lt;chr&amp;gt;,
#&amp;gt; #   temperature_dewpoint &amp;lt;dbl&amp;gt;, temperature_dewpoint_quality &amp;lt;chr&amp;gt;,
#&amp;gt; #   air_pressure &amp;lt;dbl&amp;gt;, air_pressure_quality &amp;lt;chr&amp;gt;,
#&amp;gt; #   AW1_present_weather_observation_identifier &amp;lt;chr&amp;gt;,
#&amp;gt; #   AW1_automated_atmospheric_condition_code &amp;lt;chr&amp;gt;,
#&amp;gt; #   AW1_quality_automated_atmospheric_condition_code &amp;lt;chr&amp;gt;,
#&amp;gt; #   N03_original_observation &amp;lt;chr&amp;gt;, N03_original_value_text &amp;lt;chr&amp;gt;,
#&amp;gt; #   N03_units_code &amp;lt;chr&amp;gt;, N03_parameter_code &amp;lt;chr&amp;gt;, REM_remarks &amp;lt;chr&amp;gt;,
#&amp;gt; #   REM_identifier &amp;lt;chr&amp;gt;, REM_length_quantity &amp;lt;chr&amp;gt;, REM_comment &amp;lt;chr&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Optionally, you can print progress:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;isd_parse(path, progress = TRUE)
#&amp;gt; # A tibble: 2,601 × 42
#&amp;gt;    total_chars usaf_station wban_station       date  time date_flag
#&amp;gt;          &amp;lt;dbl&amp;gt;        &amp;lt;chr&amp;gt;        &amp;lt;chr&amp;gt;     &amp;lt;date&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;
#&amp;gt; 1           54       024130        99999 2016-01-01  0000         4
#&amp;gt; 2           54       024130        99999 2016-01-01  0100         4
#&amp;gt; 3           54       024130        99999 2016-01-01  0200         4
#&amp;gt; 4           54       024130        99999 2016-01-01  0300         4
#&amp;gt; 5           54       024130        99999 2016-01-01  0400         4
#&amp;gt; 6           39       024130        99999 2016-01-01  0500         4
#&amp;gt; 7           54       024130        99999 2016-01-01  0600         4
#&amp;gt; 8           39       024130        99999 2016-01-01  0700         4
#&amp;gt; 9           54       024130        99999 2016-01-01  0800         4
#&amp;gt; 10          54       024130        99999 2016-01-01  0900         4
#&amp;gt; # ... with 2,591 more rows, and 36 more variables: latitude &amp;lt;dbl&amp;gt;,
#&amp;gt; #   longitude &amp;lt;dbl&amp;gt;, type_code &amp;lt;chr&amp;gt;, elevation &amp;lt;dbl&amp;gt;, call_letter &amp;lt;chr&amp;gt;,
#&amp;gt; #   quality &amp;lt;chr&amp;gt;, wind_direction &amp;lt;dbl&amp;gt;, wind_direction_quality &amp;lt;chr&amp;gt;,
#&amp;gt; #   wind_code &amp;lt;chr&amp;gt;, wind_speed &amp;lt;dbl&amp;gt;, wind_speed_quality &amp;lt;chr&amp;gt;,
#&amp;gt; #   ceiling_height &amp;lt;chr&amp;gt;, ceiling_height_quality &amp;lt;chr&amp;gt;,
#&amp;gt; #   ceiling_height_determination &amp;lt;chr&amp;gt;, ceiling_height_cavok &amp;lt;chr&amp;gt;,
#&amp;gt; #   visibility_distance &amp;lt;chr&amp;gt;, visibility_distance_quality &amp;lt;chr&amp;gt;,
#&amp;gt; #   visibility_code &amp;lt;chr&amp;gt;, visibility_code_quality &amp;lt;chr&amp;gt;,
#&amp;gt; #   temperature &amp;lt;dbl&amp;gt;, temperature_quality &amp;lt;chr&amp;gt;,
#&amp;gt; #   temperature_dewpoint &amp;lt;dbl&amp;gt;, temperature_dewpoint_quality &amp;lt;chr&amp;gt;,
#&amp;gt; #   air_pressure &amp;lt;dbl&amp;gt;, air_pressure_quality &amp;lt;chr&amp;gt;,
#&amp;gt; #   AW1_present_weather_observation_identifier &amp;lt;chr&amp;gt;,
#&amp;gt; #   AW1_automated_atmospheric_condition_code &amp;lt;chr&amp;gt;,
#&amp;gt; #   AW1_quality_automated_atmospheric_condition_code &amp;lt;chr&amp;gt;,
#&amp;gt; #   N03_original_observation &amp;lt;chr&amp;gt;, N03_original_value_text &amp;lt;chr&amp;gt;,
#&amp;gt; #   N03_units_code &amp;lt;chr&amp;gt;, N03_parameter_code &amp;lt;chr&amp;gt;, REM_remarks &amp;lt;chr&amp;gt;,
#&amp;gt; #   REM_identifier &amp;lt;chr&amp;gt;, REM_length_quantity &amp;lt;chr&amp;gt;, REM_comment &amp;lt;chr&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There&amp;rsquo;s a parallel option as well, coming in handy with the larger ISD files:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;isd_parse(path, parallel = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;visualize-the-data&#34;&gt;Visualize the data&lt;/h2&gt;

&lt;p&gt;Make better date + time&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;df &amp;lt;- res %&amp;gt;%
  rowwise() %&amp;gt;%
  mutate(
    datetime = as.POSIXct(strptime(paste(date, paste0(substring(time, 1, 2), &amp;quot;:00:00&amp;quot;)), &amp;quot;%Y-%m-%d %H:%M:%S&amp;quot;))
  ) %&amp;gt;%
  ungroup
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;viz&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# removing some outliers (obs, look into more for serious use)
library(ggplot2)
ggplot(df[df$temperature &amp;lt; 100,], aes(datetime, temperature)) +
  geom_point() +
  theme_grey(base_size = 18)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2016-11-03-isdparser-release/unnamed-chunk-11-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-11&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;future-work&#34;&gt;Future work&lt;/h2&gt;

&lt;p&gt;I plan to improve performance via profiling and swapping out slower code for faster,
as well as possibly dropping down to C++.&lt;/p&gt;

&lt;p&gt;There was already a featur request for asking for fields of interest instead of
getting all fields, so &lt;a href=&#34;https://github.com/ropenscilabs/isdparser/issues/8&#34;&gt;that&amp;rsquo;s on the list&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Do try out &lt;code&gt;isdparser&lt;/code&gt;. Let us know of any bugs, and any feature requests!&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Overlaying species occurrence data with climate data</title>
      <link>https://ropensci.org/blog/2014/04/22/rwbclimate-sp/</link>
      <pubDate>Tue, 22 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2014/04/22/rwbclimate-sp/</guid>
      <description>
        
        &lt;p&gt;One of the goals of the rOpenSci is to facilitate interoperability between different data sources around web with our tools.  We can achieve this by providing functionality within our packages that converts data coming down via web APIs in one format (often a provider specific schema) into a standard format.  The new version of &lt;a href=&#34;http://github.com/ropensci/rwbclimate&#34;&gt;rWBclimate&lt;/a&gt; that we just posted to &lt;a href=&#34;http://cran.r-project.org/web/packages/rWBclimate/index.html&#34;&gt;CRAN&lt;/a&gt; does just that.  In an &lt;a href=&#34;http://www.ropensci.org/blog/2013/07/29/rWBclimate-rgbif/&#34;&gt;earlier post&lt;/a&gt; I wrote about how users could combine data from both &lt;a href=&#34;http://github.com/ropensci/rgbif&#34;&gt;rgbif&lt;/a&gt; and &lt;code&gt;rWBclimate&lt;/code&gt;. Back then I just thought it was pretty cool that you could overlay the points on a nice climate map.  Now we&amp;rsquo;ve come a long way, with the development of an easier to use and more comprehensive package for accessing species occurrence data, &lt;a href=&#34;http://github.com/ropensci/spocc&#34;&gt;spocc&lt;/a&gt;, and added conversion functions to create spatial objects out of both climate data maps, and species occurrence data.  The result is that you can grab data from both sources, and then extract climate information about your species occurrence data.&lt;/p&gt;

&lt;p&gt;In the example below I&amp;rsquo;m going to download climate data at the basin level for the US and Mexico, and then species occurrences for eight different tree species.  I&amp;rsquo;ll then extract the temperature from each point data with an spatial overlay and look at the distribution of temperatures for each species.  Furthermore the conversion to spatial objects functions will allow you to use our data with any &lt;a href=&#34;http://en.wikipedia.org/wiki/Shapefile&#34;&gt;shape files&lt;/a&gt; you might have.&lt;/p&gt;

&lt;p&gt;The first step is to grab the &lt;a href=&#34;https://developers.google.com/kml/documentation/&#34;&gt;KML&lt;/a&gt; files for each river basin making up the US and Mexico, which we &lt;a href=&#34;http://data.worldbank.org/sites/default/files/climate_data_api_basins.pdf&#34;&gt;identify with an integer&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;
library(&amp;quot;rWBclimate&amp;quot;)
# Install spocc from our GitHub repo
# devtools::install_github(&amp;quot;spocc&amp;quot;, &amp;quot;ropensci&amp;quot;)
library(&amp;quot;spocc&amp;quot;)
library(&amp;quot;taxize&amp;quot;)
library(&amp;quot;plyr&amp;quot;)
library(&amp;quot;sp&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(spocc)
### Create path to store kml&#39;s
dir.create(&amp;quot;~/kmltmp&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;options(kmlpath = &amp;quot;~/kmltmp&amp;quot;)
options(stringsAsFactors = FALSE)

usmex &amp;lt;- c(273:284, 328:365)
### Download KML&#39;s and read them in.
usmex.basin &amp;lt;- create_map_df(usmex)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;

## Download temperature data
temp.dat &amp;lt;- get_historical_temp(usmex, &amp;quot;decade&amp;quot;)
temp.dat &amp;lt;- subset(temp.dat, temp.dat$year == 2000)


# Bind temperature data to map data frame

usmex.map.df &amp;lt;- climate_map(usmex.basin, temp.dat, return_map = F)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we have created a map of the US and Mexico, downloaded the average temperature in each basin between 1990 and 2000, and bound them together.  Next let&amp;rsquo;s grab occurrence data using &lt;code&gt;spocc&lt;/code&gt; for our eight tree species (&lt;em&gt;Note:  &lt;code&gt;rgbif&lt;/code&gt; &amp;gt; 0.6.0 needs to be installed to work properly&lt;/em&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;
## Grab some species occurrence data for the 8 tree species.

splist &amp;lt;- c(&amp;quot;Acer saccharum&amp;quot;, &amp;quot;Abies balsamea&amp;quot;, &amp;quot;Arbutus xalapensis&amp;quot;, &amp;quot;Betula alleghaniensis&amp;quot;, &amp;quot;Chilopsis linearis&amp;quot;, &amp;quot;Conocarpus erectus&amp;quot;, &amp;quot;Populus tremuloides&amp;quot;, &amp;quot;Larix laricina&amp;quot;)

## get data from bison and gbif
splist &amp;lt;- sort(splist)
out &amp;lt;- occ(query = splist, from = c(&amp;quot;bison&amp;quot;, &amp;quot;gbif&amp;quot;), limit = 100)

## scrub names
out &amp;lt;- fixnames(out, how = &amp;quot;query&amp;quot;)

## Create a data frame of all data.

out_df &amp;lt;- occ2df(out)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we&amp;rsquo;ve downloaded the data using their latin names, we might want to know the common names.  Luckily the &lt;code&gt;taxize&lt;/code&gt; package is great for that, and we can grab them with just a couple of lines of code.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;
### grab common names
cname &amp;lt;- ldply(sci2comm(get_tsn(splist), db = &amp;quot;itis&amp;quot;, simplify = TRUE), function(x) { return(x[1]) })[, 2]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;### Now let&#39;s create a vector of common names for easy plotting But first
### order on names so we can just add the names
out_df &amp;lt;- out_df[order(out_df$name), ]
### strip NA values and 0 values of coordinates
out_df &amp;lt;- out_df[!is.na(out_df$lat), ]
out_df &amp;lt;- out_df[out_df$lat &amp;gt; 0, ]
out_df$common &amp;lt;- rep(cname, table(out_df$name))

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we have all the components we need, species data and spatial polygons with temperature data bound to them.  Before we do the spatial over lay, let&amp;rsquo;s have do a quick visualization.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;
## Now just create the base temperature map
usmex.map &amp;lt;- ggplot() +
  geom_polygon(data = usmex.map.df, aes(x = long, y = lat, group = group, fill = data, alpha = 0.9)) +
  scale_fill_continuous(&amp;quot;Average annual \n temp: 1990-2000&amp;quot;, low = &amp;quot;yellow&amp;quot;, high = &amp;quot;red&amp;quot;) +
  guides(alpha = F) +
  theme_bw(10)

## And overlay of gbif data
usmex.map &amp;lt;- usmex.map +
  geom_point(data = out_df, aes(y = latitude, x = longitude, group = common, colour = common)) +
  xlim(-125, -59) +
  ylim(5, 55)

print(usmex.map)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-04-22-rwbclimate-sp/mapping_2.png&#34; alt=&#34;plot of chunk mapping&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now the question is, what&amp;rsquo;s the temperature at each point for each tree species?  We can convert our species data to spatial points with &lt;code&gt;occ_to_sp&lt;/code&gt;, and our data from &lt;code&gt;rWBclimate&lt;/code&gt; can be converted to spatial polygons with &lt;code&gt;kml_to_sp&lt;/code&gt;.  Next we can loop through each grouping of species, and call the &lt;code&gt;over&lt;/code&gt; function to get the temperature at each point.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Create a spatial polygon dataframe binding kml polygons to temperature
## data
temp_sdf &amp;lt;- kml_to_sp(usmex.basin, df = temp.dat)
### Now we can change the points to a spatial polygon:
sp_points &amp;lt;- occ_to_sp(out)

tdat &amp;lt;- vector()
### Get averages
for (i in 1:length(splist)) {
    tmp_sp &amp;lt;- sp_points[which(sp_points$name == splist[i]), ]
    tmp_t &amp;lt;- over(tmp_sp, temp_sdf)$data
    tdat &amp;lt;- c(tdat, tmp_t)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The last step is to create a new data frame with our data.  Unfortunately the size of our old data frame &lt;code&gt;out_df&lt;/code&gt; won&amp;rsquo;t be the same size due to some invalid lat/long&amp;rsquo;s that came down with our data so the entire data frame will be reassembled.  After we assemble the data frame we can summarize our it with plyr, getting the mean temperature and latitude for each species.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;
### Assemble new dataframe
spDF &amp;lt;- data.frame(matrix(nrow = dim(sp_points)[1], ncol = 0))
spDF$species &amp;lt;- sp_points$name
spDF &amp;lt;- cbind(coordinates(sp_points), spDF)

### This is important, be sure to order all the points alphebetically as we
### did earlier
spDF &amp;lt;- spDF[order(spDF$species), ]

spDF$cname &amp;lt;- rep(cname, table(sp_points$name))
spDF$temp &amp;lt;- tdat
### Strip NA&#39;s
spDF &amp;lt;- spDF[!is.na(spDF$temp), ]

## Create summary
summary_data &amp;lt;- ddply(spDF, .(cname), summarise, mlat = mean(latitude), mtemp = mean(temp),
    sdlat = sd(latitude), sdtemp = sd(temp))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;First let&amp;rsquo;s look at a plot of mean temperature vs latititude, and to identify the points we&amp;rsquo;ll plot their common names.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(summary_data, aes(x = mlat, y = mtemp, label = cname)) +
  geom_text() +
  xlab(&amp;quot;Mean Latitude&amp;quot;) +
  ylab(&amp;quot;Mean Temperature (C)&amp;quot;) +
  theme_bw() +
  xlim(10, 50)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-04-22-rwbclimate-sp/means.png&#34; alt=&#34;plot of chunk means&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This gives us a sense about how the means of each value are related, but we can also look at the distribution of temperatures with boxplots.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(spDF, aes(as.factor(cname), temp)) +
  geom_boxplot() +
  theme_bw(13) +
  ylab(&amp;quot;Temperature&amp;quot;) +
  xlab(&amp;quot;Common Name&amp;quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-04-22-rwbclimate-sp/boxplots.png&#34; alt=&#34;plot of chunk boxplots&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This gives a sense of how wide the temperature distributions are, as well as looking at some of the outliers.  The distributions look pretty skewed, and this probably reflects the large spatial granularity of our temperature data compared to the occurrence data.  However this example shows how you can easily combine data from multiple rOpenSci packages.  We will continue to work towards enhancing the interoperability of heterogeneous data streams via our tools.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>rnoaa - Access to NOAA National Climatic Data Center data</title>
      <link>https://ropensci.org/blog/2014/03/13/rnoaa/</link>
      <pubDate>Thu, 13 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2014/03/13/rnoaa/</guid>
      <description>
        
        

&lt;p&gt;We recently pushed the first version of &lt;code&gt;rnoaa&lt;/code&gt; to CRAN - version 0.1. NOAA has a lot of data, some of which is provided via the &lt;a href=&#34;http://www.ncdc.noaa.gov/&#34;&gt;National Climatic Data Center&lt;/a&gt;, or NCDC. NOAA has provided access to NCDC climate data via a RESTful API - which is great because people like us can create clients for different programming languages to access their data programatically. If you are so inclined to write a bit of R code, this means you can get to NCDC data in the R environment where your workflow is reproducible, and you can connect data acquisition to a suite of tools for data manipulation (e.g., &lt;code&gt;plyr&lt;/code&gt;), visualization (e.g., &lt;code&gt;ggplot2&lt;/code&gt;), and statistics (e.g., &lt;code&gt;lme4&lt;/code&gt;, etc.).&lt;/p&gt;

&lt;p&gt;In addition to NCDC climate data, we have functions to access sea ice cover data via FTP, as well as the Severe Weather Data Inventory (SWDI) via API. We will continue to add in other data sources as we have time.&lt;/p&gt;

&lt;p&gt;Some notes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The docs for the API are live at the &lt;a href=&#34;http://www.ncdc.noaa.gov/cdo-web/webservices/v2&#34;&gt;NOAA NCDC website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GCHN Daily data is also available via &lt;a href=&#34;http://www.ncdc.noaa.gov/oa/climate/ghcn-daily/&#34;&gt;FTP&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The below examples uses the development version, but most things can be done with the CRAN version. Here&amp;rsquo;s a quick run down of some things you can do with &lt;code&gt;rnoaa&lt;/code&gt;:&lt;/p&gt;

&lt;h2 id=&#34;first-install-and-load-taxize&#34;&gt;First, install and load taxize&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;rnoaa&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;or development version from GitHub&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;devtools&amp;quot;)
library(devtools)
install_github(&amp;quot;rnoaa&amp;quot;, &amp;quot;ropensci&amp;quot;)
library(rnoaa)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(rnoaa)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;api-keys-authentication&#34;&gt;API keys - authentication&lt;/h2&gt;

&lt;p&gt;You&amp;rsquo;ll need an API key to use this package (essentially a password). Go to the &lt;a href=&#34;http://www.ncdc.noaa.gov/cdo-web/token&#34;&gt;NCDC website&lt;/a&gt; to get one. &lt;em&gt;You can&amp;rsquo;t use this package without an API key.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Once you obtain a key, there are two ways to use it.&lt;/p&gt;

&lt;p&gt;a) Pass it inline with each function call (somewhat cumbersome and wordy)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;noaa(datasetid = &amp;quot;PRECIP_HLY&amp;quot;, locationid = &amp;quot;ZIP:28801&amp;quot;, datatypeid = &amp;quot;HPCP&amp;quot;,
    limit = 5, token = &amp;quot;YOUR_TOKEN&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;b) Alternatively, you might find it easier to set this as an option, either by adding this line to the top of a script or somewhere in your &lt;code&gt;.Rprofile&lt;/code&gt; file&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;options(noaakey = &amp;quot;KEY_EMAILED_TO_YOU&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Specifically use the name &lt;em&gt;noaakey&lt;/em&gt; as the functions in the &lt;code&gt;rnoaa&lt;/code&gt; package are looking for a key by that name.&lt;/p&gt;

&lt;h2 id=&#34;fetch-list-of-city-locations-in-descending-order&#34;&gt;Fetch list of city locations in descending order&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;noaa_locs(locationcategoryid = &amp;quot;CITY&amp;quot;, sortfield = &amp;quot;name&amp;quot;, sortorder = &amp;quot;desc&amp;quot;,
    limit = 5)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $meta
## $meta$totalCount
## [1] 1654
##
## $meta$pageCount
## [1] 5
##
## $meta$offset
## [1] 1
##
##
## $data
##              id           name datacoverage    mindate    maxdate
## 1 CITY:NL000012     Zwolle, NL       1.0000 1892-08-01 2014-01-31
## 2 CITY:SZ000007     Zurich, SZ       1.0000 1901-01-01 2014-03-11
## 3 CITY:NG000004     Zinder, NG       0.8678 1906-01-01 1980-12-31
## 4 CITY:UP000025  Zhytomyra, UP       0.9726 1938-01-01 2014-03-11
## 5 CITY:KZ000017 Zhezkazgan, KZ       0.9279 1948-03-01 2014-03-10
##
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;noaa_locs&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;get-info-on-a-station-by-specifcying-a-dataset-locationtype-location-and-station&#34;&gt;Get info on a station by specifcying a dataset, locationtype, location, and station&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;noaa_stations(datasetid = &amp;quot;GHCND&amp;quot;, locationid = &amp;quot;FIPS:12017&amp;quot;, stationid = &amp;quot;GHCND:USC00084289&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $meta
## NULL
##
## $data
##                  id                  name datacoverage    mindate
## 1 GHCND:USC00084289 INVERNESS 3 SE, FL US            1 1899-02-01
##      maxdate
## 1 2014-03-12
##
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;noaa_stations&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;search-for-data&#34;&gt;Search for data&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;out &amp;lt;- noaa(datasetid = &amp;quot;GHCND&amp;quot;, stationid = &amp;quot;GHCND:USW00014895&amp;quot;, datatypeid = &amp;quot;PRCP&amp;quot;,
    startdate = &amp;quot;2010-05-01&amp;quot;, enddate = &amp;quot;2010-10-31&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;see-a-data-frame&#34;&gt;See a data.frame&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(out$data)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##             station value attributes datatype                date
## 1 GHCND:USW00014895     0  T,,0,2400     PRCP 2010-05-01T00:00:00
## 2 GHCND:USW00014895    30   ,,0,2400     PRCP 2010-05-02T00:00:00
## 3 GHCND:USW00014895    51   ,,0,2400     PRCP 2010-05-03T00:00:00
## 4 GHCND:USW00014895     0  T,,0,2400     PRCP 2010-05-04T00:00:00
## 5 GHCND:USW00014895    18   ,,0,2400     PRCP 2010-05-05T00:00:00
## 6 GHCND:USW00014895    30   ,,0,2400     PRCP 2010-05-06T00:00:00
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;get-table-of-all-datasets&#34;&gt;Get table of all datasets&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res &amp;lt;- noaa_datasets()
res$data
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##                     uid         id                    name datacoverage
## 1  gov.noaa.ncdc:C00040     ANNUAL        Annual Summaries         1.00
## 2  gov.noaa.ncdc:C00861      GHCND         Daily Summaries         1.00
## 3  gov.noaa.ncdc:C00841    GHCNDMS       Monthly Summaries         1.00
## 4  gov.noaa.ncdc:C00345    NEXRAD2         Nexrad Level II         0.95
## 5  gov.noaa.ncdc:C00708    NEXRAD3        Nexrad Level III         0.95
## 6  gov.noaa.ncdc:C00821 NORMAL_ANN Normals Annual/Seasonal         1.00
## 7  gov.noaa.ncdc:C00823 NORMAL_DLY           Normals Daily         1.00
## 8  gov.noaa.ncdc:C00824 NORMAL_HLY          Normals Hourly         1.00
## 9  gov.noaa.ncdc:C00822 NORMAL_MLY         Normals Monthly         1.00
## 10 gov.noaa.ncdc:C00505  PRECIP_15 Precipitation 15 Minute         0.25
## 11 gov.noaa.ncdc:C00313 PRECIP_HLY    Precipitation Hourly         1.00
##       mindate    maxdate
## 1  1831-02-01 2013-11-01
## 2  1763-01-01 2014-03-13
## 3  1763-01-01 2014-01-01
## 4  1991-06-05 2014-03-12
## 5  1994-05-20 2014-03-09
## 6  2010-01-01 2010-01-01
## 7  2010-01-01 2010-12-31
## 8  2010-01-01 2010-12-31
## 9  2010-01-01 2010-12-01
## 10 1970-05-12 2013-03-01
## 11 1900-01-01 2013-03-01
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;get-data-category-data-and-metadata&#34;&gt;Get data category data and metadata&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;noaa_datacats(locationid = &amp;quot;CITY:US390029&amp;quot;, limit = 5)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $meta
## $meta$totalCount
## [1] 37
##
## $meta$pageCount
## [1] 5
##
## $meta$offset
## [1] 1
##
##
## $data
##        id                 name
## 1  ANNAGR  Annual Agricultural
## 2   ANNDD   Annual Degree Days
## 3 ANNPRCP Annual Precipitation
## 4 ANNTEMP   Annual Temperature
## 5   AUAGR  Autumn Agricultural
##
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;noaa_datacats&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;plotting&#34;&gt;Plotting&lt;/h2&gt;

&lt;h3 id=&#34;plot-data-super-simple-but-it-s-a-start&#34;&gt;Plot data, super simple, but it&amp;rsquo;s a start&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;out &amp;lt;- noaa(datasetid = &amp;quot;GHCND&amp;quot;, stationid = &amp;quot;GHCND:USW00014895&amp;quot;, datatypeid = &amp;quot;PRCP&amp;quot;,
    startdate = &amp;quot;2010-05-01&amp;quot;, enddate = &amp;quot;2010-10-31&amp;quot;, limit = 500)
noaa_plot(out, breaks = &amp;quot;1 month&amp;quot;, dateformat = &amp;quot;%d/%m&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-03-13-rnoaa/unnamed-chunk-12.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;more-plotting&#34;&gt;More plotting&lt;/h3&gt;

&lt;p&gt;You can pass many outputs from calls to the &lt;code&gt;noaa&lt;/code&gt; function in to the &lt;code&gt;noaa_plot&lt;/code&gt; function.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;out1 &amp;lt;- noaa(datasetid = &amp;quot;GHCND&amp;quot;, stationid = &amp;quot;GHCND:USW00014895&amp;quot;, datatypeid = &amp;quot;PRCP&amp;quot;,
    startdate = &amp;quot;2010-03-01&amp;quot;, enddate = &amp;quot;2010-05-31&amp;quot;, limit = 500)
out2 &amp;lt;- noaa(datasetid = &amp;quot;GHCND&amp;quot;, stationid = &amp;quot;GHCND:USW00014895&amp;quot;, datatypeid = &amp;quot;PRCP&amp;quot;,
    startdate = &amp;quot;2010-09-01&amp;quot;, enddate = &amp;quot;2010-10-31&amp;quot;, limit = 500)
noaa_plot(out1, out2, breaks = &amp;quot;45 days&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-03-13-rnoaa/unnamed-chunk-13.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;sea-ice-cover-data&#34;&gt;Sea ice cover data&lt;/h2&gt;

&lt;p&gt;Get urls for ftp files&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;urls &amp;lt;- sapply(seq(1979, 1990, 1), function(x) seaiceeurls(yr = x, mo = &amp;quot;Feb&amp;quot;,
    pole = &amp;quot;S&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Call the &lt;code&gt;noaa_seaice&lt;/code&gt; function on each url, which downloads shape files, and reads them in to R as &lt;code&gt;sp&lt;/code&gt; objects&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;out &amp;lt;- lapply(urls, noaa_seaice)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then plot&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(plyr)
library(ggplot2)
names(out) &amp;lt;- seq(1979, 1990, 1)
df &amp;lt;- ldply(out)
ggplot(df, aes(long, lat, group = group)) + geom_polygon(fill = &amp;quot;steelblue&amp;quot;) +
    theme_ice() + facet_wrap(~.id)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-03-13-rnoaa/unnamed-chunk-16.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;severe-weather-data&#34;&gt;Severe weather data&lt;/h2&gt;

&lt;h3 id=&#34;search-for-nx3tvs-data-from-5-may-2006-to-6-may-2006&#34;&gt;Search for nx3tvs data from 5 May 2006 to 6 May 2006&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;noaa_swdi(dataset = &amp;quot;nx3tvs&amp;quot;, startdate = &amp;quot;20060505&amp;quot;, enddate = &amp;quot;20060506&amp;quot;,
    limit = 3)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $meta
## $meta$totalCount
## [1] 3
##
## $meta$totalTimeInSeconds
## [1] 0.004
##
##
## $data
##                  ztime wsr_id cell_id cell_type range azimuth max_shear
## 1 2006-05-05T00:05:50Z   KBMX      Q0       TVS     7     217       403
## 2 2006-05-05T00:10:02Z   KBMX      Q0       TVS     5     208       421
## 3 2006-05-05T00:12:34Z   KSJT      P2       TVS    49     106        17
##   mxdv
## 1  116
## 2  120
## 3   52
##
## $shape
##                                        shape
## 1 POINT (-86.8535716274277 33.0786326913943)
## 2 POINT (-86.8165772540846 33.0982820681588)
## 3 POINT (-99.5771091971025 31.1421609654838)
##
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;noaa_swdi&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;get-all-plsr-within-the-bounding-box-91-30-90-31&#34;&gt;Get all &amp;lsquo;plsr&amp;rsquo; within the bounding box (-91,30,-90,31)&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;noaa_swdi(dataset = &amp;quot;plsr&amp;quot;, startdate = &amp;quot;20060505&amp;quot;, enddate = &amp;quot;20060510&amp;quot;, bbox = c(-91,
    30, -90, 31), limit = 3)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $meta
## $meta$totalCount
## [1] 3
##
## $meta$totalTimeInSeconds
## [1] 0.015
##
##
## $data
##                  ztime     id        event magnitude         city
## 1 2006-05-09T02:20:00Z 427540         HAIL         1 5 E KENTWOOD
## 2 2006-05-09T02:40:00Z 427536         HAIL         1 MOUNT HERMAN
## 3 2006-05-09T02:40:00Z 427537 TSTM WND DMG     -9999 MOUNT HERMAN
##       county state          source
## 1 TANGIPAHOA    LA TRAINED SPOTTER
## 2 WASHINGTON    LA TRAINED SPOTTER
## 3 WASHINGTON    LA TRAINED SPOTTER
##
## $shape
##                  shape
## 1 POINT (-90.43 30.93)
## 2  POINT (-90.3 30.96)
## 3  POINT (-90.3 30.96)
##
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;noaa_swdi&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;get-all-nx3tvs-within-the-tile-102-1-32-6&#34;&gt;Get all &amp;lsquo;nx3tvs&amp;rsquo; within the tile -102.&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;32&lt;/sub&gt;.6&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;noaa_swdi(dataset = &amp;quot;nx3tvs&amp;quot;, startdate = &amp;quot;20060506&amp;quot;, enddate = &amp;quot;20060507&amp;quot;,
    tile = c(-102.12, 32.62), limit = 3)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $meta
## $meta$totalCount
## [1] 3
##
## $meta$totalTimeInSeconds
## [1] 0.021
##
##
## $data
##                  ztime wsr_id cell_id cell_type range azimuth max_shear
## 1 2006-05-06T00:41:29Z   KMAF      D9       TVS    37       6        39
## 2 2006-05-06T03:56:18Z   KMAF      N4       TVS    39       3        30
## 3 2006-05-06T03:56:18Z   KMAF      N4       TVS    42       4        20
##   mxdv
## 1   85
## 2   73
## 3   52
##
## $shape
##                                        shape
## 1 POINT (-102.112726356403 32.5574494581267)
## 2  POINT (-102.14873079873 32.5933553250156)
## 3 POINT (-102.131167022161 32.6426287452898)
##
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;noaa_swdi&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;counts&#34;&gt;Counts&lt;/h3&gt;

&lt;p&gt;Get number of &amp;lsquo;nx3tvs&amp;rsquo; within 15 miles of latitude = 32.7 and longitude = -102.0&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;noaa_swdi(dataset = &amp;quot;nx3tvs&amp;quot;, startdate = &amp;quot;20060505&amp;quot;, enddate = &amp;quot;20060516&amp;quot;,
    radius = 15, center = c(-102, 32.7), stat = &amp;quot;count&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $meta
## $meta$totalCount
## [1] 1
##
## $meta$totalTimeInSeconds
## [1] 0.02
##
##
## $data
## [1] &amp;quot;37&amp;quot;
##
## $shape
## data frame with 0 columns and 1 rows
##
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;noaa_swdi&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

      </description>
    </item>
    
    <item>
      <title>Overlaying climate data with species occurrence data</title>
      <link>https://ropensci.org/blog/2013/07/29/rwbclimate-rgbif/</link>
      <pubDate>Mon, 29 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2013/07/29/rwbclimate-rgbif/</guid>
      <description>
        
        

&lt;p&gt;One of our primary goals at ROpenSci is to wrap as many science API&amp;rsquo;s as possible.  While each package can be used as a standalone interface, there&amp;rsquo;s lots of ways our packages can overlap and complement each other.  Sure &lt;a href=&#34;http://www.youtube.com/watch?v=7yeA7a0uS3A&#34;&gt;He-Man&lt;/a&gt; usually rode &lt;a href=&#34;http://en.wikipedia.org/wiki/Battle_Cat&#34;&gt;Battle Cat&lt;/a&gt;, but there&amp;rsquo;s no reason he couldn&amp;rsquo;t ride a &lt;a href=&#34;http://drawception.com/pub/panels/2012/5-14/swgpnXLCRm-8.png&#34;&gt;my little pony&lt;/a&gt; sometimes too.  That&amp;rsquo;s the case with our packages for &lt;a href=&#34;http://www.gbif.org/&#34;&gt;GBIF&lt;/a&gt; and the &lt;a href=&#34;http://data.worldbank.org/developers/climate-data-api&#34;&gt;worldbank climate data api&lt;/a&gt;.  Both packages will give you lots and lots of data, but a shared feature of both is the ability to plot spatial information.  The &lt;a href=&#34;https://github.com/ropensci/rWBclimate&#34;&gt;rWBclimate&lt;/a&gt; package provides a robust mapping ability on top of access to climate data.  At it&amp;rsquo;s most bare bones, it can be used as alternative to the built in mapping facilities included in &lt;a href=&#34;https://github.com/ropensci/rgbif/&#34;&gt;rgbif&lt;/a&gt;.  Building on the example in the &lt;a href=&#34;http://www.ropensci.org/tutorials/rgbif_tutorial.html#occurrencelist&#34;&gt;rgbif tutorial&lt;/a&gt; we&amp;rsquo;ll plot data for two species in the US and Mexico, the dark eyed junco (&lt;em&gt;Junco hyemalis&lt;/em&gt;) and the wood duck (&lt;em&gt;Aix sponsa&lt;/em&gt;).  Here&amp;rsquo;s how you can use the kml interface from rWBclimate to download a map of the US and Mexico and overlay it with data from rgbif.
&lt;br&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;
library(ggplot2)
library(rWBclimate)
library(rgbif)
## Grab some occurrence data

splist &amp;lt;- c(&amp;quot;Junco hyemalis&amp;quot;, &amp;quot;Aix sponsa&amp;quot;)
out &amp;lt;- occurrencelist_many(splist, coordinatestatus = TRUE, maxresults = 1000)

## Set the map data path
options(kmlpath = &amp;quot;/Users/edmundhart/kmltemp&amp;quot;)
sp.map.df &amp;lt;- create_map_df(c(&amp;quot;USA&amp;quot;,&amp;quot;MEX&amp;quot;))

## create map plot
sp.map &amp;lt;- ggplot(sp.map.df,aes(x=long,y=lat,group=group))+geom_polygon(fill=&amp;quot;white&amp;quot;,colour=&amp;quot;black&amp;quot;)+xlim(-130,-65)+ylim(12,50)

## Overlay occurrence data
sp.map + geom_point(data=gbifdata(out),aes(y=decimalLatitude,x=decimalLongitude,group=taxonName,colour=taxonName))

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
&lt;img src=&#34;https://ropensci.org/assets/blog-images/2013-07-29-rWBclimate-rgbif/gbifmap1.png&#34; alt=&#34;center&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;overlaying-climate-data-with-occurrence-data&#34;&gt;Overlaying climate data with occurrence data&lt;/h2&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;So that&amp;rsquo;s how you could make a basic map, but what if you want to overlay climate data with occurrence data?  That&amp;rsquo;s easy too.  You repeat essentially the same steps as above, but be sure to grab some climate data too. In this example I&amp;rsquo;ve chose to grab data for 8 different tree species that exhibit somewhat of a lattitudinal gradient.  I&amp;rsquo;ll map them on top of historical temperature data.  In this case I&amp;rsquo;ll be using the average annual temperature from 1990 to 2000.  Because I want a bit better spatial resolution I&amp;rsquo;ll be using basin level data instead of country level data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;
### Download map data
usmex &amp;lt;- c(273:284,328:365)
usmex.basin &amp;lt;- create_map_df(usmex)

## Download temperature data
temp.dat &amp;lt;- get_historical_temp(usmex, &amp;quot;decade&amp;quot; )
temp.dat &amp;lt;- subset(temp.dat,temp.dat$year == 2000 )


#create my climate map
usmex.map.df &amp;lt;- climate_map(usmex.basin,temp.dat,return_map=F)


## Grab some species occurrence data for the 8 tree species.

splist &amp;lt;- c(&amp;quot;Acer saccharum&amp;quot;,
            &amp;quot;Abies balsamea&amp;quot;,
            &amp;quot;Arbutus texana&amp;quot;,
            &amp;quot;Betula alleghaniensis&amp;quot;,
            &amp;quot;Chilopsis linearis&amp;quot;,
            &amp;quot;Conocarpus erectus&amp;quot;,
            &amp;quot;Populus tremuloides&amp;quot;,
            &amp;quot;Larix laricina&amp;quot;)
out &amp;lt;- occurrencelist_many(splist, coordinatestatus=TRUE, maxresults=1000, fixnames=&amp;quot;match&amp;quot;)

## Now just create the base temperature map
usmex.map &amp;lt;- ggplot()+geom_polygon(data=usmex.map.df,aes(x=long,y=lat,group=group,fill=data,alpha=.8))+scale_fill_continuous(&amp;quot;Average annual \n temp: 1990-2000&amp;quot;,low=&amp;quot;yellow&amp;quot;,high=&amp;quot;red&amp;quot;)+ guides(alpha=F)+theme_bw()


## And overlay of gbif data
usmex.map + geom_point(data=gbifdata(out),aes(y=decimalLatitude,x=decimalLongitude,group=taxonName,colour= taxonName)) + xlim(-125,-59)+ylim(5,55)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
&lt;img src=&#34;https://ropensci.org/assets/blog-images/2013-07-29-rWBclimate-rgbif/gbifmap2.png&#34; alt=&#34;center&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The map doesn&amp;rsquo;t have borders because it&amp;rsquo;s created at the basin level, but it would be easy enough to add an outline for the countries.  You could also plot any of your own data over climate maps because they are based on decimal lattitude and longitude coordinates, or data from multiple sources.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Making maps of climate change</title>
      <link>https://ropensci.org/blog/2013/07/19/rwbclimate-maps/</link>
      <pubDate>Fri, 19 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2013/07/19/rwbclimate-maps/</guid>
      <description>
        
        

&lt;p&gt;A recent video on the &lt;a href=&#34;http://video.pbs.org/program/idea-channel/&#34;&gt;PBS Ideas Channel&lt;/a&gt; posited that the discovery of &lt;a href=&#34;http://www.youtube.com/watch?v=1M1BPz0nY3s&#34;&gt;climate change is humanities greatest scientific achievement&lt;/a&gt;. It took synthesizing generations of data from thousands of scientists, hundreds of thousands (if not more) of hours of computer time to run models at institutions all over the world.  But how can the individual researcher get their hands of some this data?  Right now the &lt;a href=&#34;http://www.worldbank.org&#34;&gt;World Bank&lt;/a&gt; provides access to global circulation model (GCM) output from between 1900 and 2100 in 20 year intervals via their &lt;a href=&#34;http://data.worldbank.org/developers/climate-data-api&#34;&gt;climate data api&lt;/a&gt;.  Using our new package &lt;a href=&#34;https://github.com/ropensci/rWBclimate&#34;&gt;rWBclimate&lt;/a&gt; you can access model output from 15 different GCM&amp;rsquo;s, ensemble data from all GCM&amp;rsquo;s aggregated, and historical climate data.  This data is available at two different spatial scales, individual countries or watershed basins. On top of access to all this data, the API provides a way to download &lt;a href=&#34;https://developers.google.com/kml/documentation/&#34;&gt;KML&lt;/a&gt; definitions for each corresponding spatial element (country or basin).  This means with our package it&amp;rsquo;s easy to download climate data and create maps of any of the thousands of datapoints you have access to via the API.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;install-rwbclimate&#34;&gt;Install rWBclimate&lt;/h2&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# install_github(&#39;rWBclimate&#39;, &#39;ropensci&#39;)
library(rWBclimate)
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;map-of-north-american-precipitation-anomalies&#34;&gt;Map of North American precipitation anomalies&lt;/h2&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Aside from access to both temperature and preciptation data, you can download anomaly data, showing the change from some time period and a control period of 1961-2009.  Let&amp;rsquo;s create a precipitation anomaly map to see how much change there will be across North America.  The first thing we&amp;rsquo;ll need to do is download the data and subset it so we have one piece of spatial information per KML polygon.  We&amp;rsquo;ll be using examples with preloaded basin ID&amp;rsquo;s, in this case &lt;em&gt;NoAm_basin&lt;/em&gt;.  However you can download data with a vector of numbers for &lt;a href=&#34;http://data.worldbank.org/sites/default/files/climate_data_api_basins.pdf&#34;&gt;basins&lt;/a&gt; or countries using three letter &lt;a href=&#34;http://unstats.un.org/unsd/methods/m49/m49alpha.htm&#34;&gt;ISO country codes&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Download data for all basins in North America in the 2080-2100 period
prp.dat &amp;lt;- get_ensemble_precip(NoAm_basin,&amp;quot;annualanom&amp;quot;,2080,2100)

#subset the data to the 50th percentile
prp.dat &amp;lt;- subset(prp.dat, prp.dat$scenario == &amp;quot;a2&amp;quot; &amp;amp; prp.dat$percentile == 50)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we should have all the data we need, we need to download the KML files to map.  rWBclimate locally stores KML files in a directory you specify until they are deleted.  You&amp;rsquo;ll need to set kmlpath in the options as follows: &lt;code&gt;options(kmlpath=&amp;quot;/Users/edmundhart/kmltemp&amp;quot;)&lt;/code&gt; KML files can be large so when first downloading it can take some time to create a map dataframe.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;options(kmlpath=&amp;quot;/Users/edmundhart/kmltemp&amp;quot;)
#First create a mapable data frame with the same basin ID&#39;s that were used to download data.
prp.map &amp;lt;- create_map_df(NoAm_basin)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that you have your data as well as your dataframe of polygons we just need to use one last function to create a map.  You have two options with this function.  It can return a dataframe that you can map yourself, or a ggplot2 map that can be modified as you see fit like in this example.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pranom.map &amp;lt;- climate_map(prp.map,prp.dat)
pranom.map &amp;lt;- pranom.map + scale_fill_continuous(&amp;quot;Precipitation \n anomaly (mm)&amp;quot;, low=&amp;quot;Red&amp;quot;,high = &amp;quot;Blue&amp;quot;)+ylab(&amp;quot;Latitude&amp;quot;)+xlab(&amp;quot;Longitude&amp;quot;) + theme_bw()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here you can see that northern latitudes are expected to get much rainier while as you move closer to the equator the climate will become drier.
&lt;img src=&#34;https://ropensci.org/assets/blog-images/2013-07-19-rWBclimate-maps/precipMap.png&#34; alt=&#34;center&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;creating-a-global-temperature-map&#34;&gt;Creating a global temperature map&lt;/h2&gt;

&lt;p&gt;&lt;br&gt;
You could also create custom global maps.  Let&amp;rsquo;s put it all together and make a world map at the basin level for temperature anomaly.  This will take a bit of time to run beacuse you&amp;rsquo;re downloading 438 kml files.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;
wtemp.dat &amp;lt;- get_ensemble_temp(1:468,&amp;quot;annualanom&amp;quot;,2080,2100)
wtemp.dat &amp;lt;- subset(wtemp.dat, wtemp.dat$scenario == &amp;quot;a2&amp;quot; &amp;amp; wtemp.dat$percentile == 50)
wtemp.map.df &amp;lt;- create_map_df(1:468)
wtemp.map &amp;lt;- climate_map(wtemp.map.df,wtemp.dat)

wtemp.map &amp;lt;- wtemp.map + scale_fill_continuous(&amp;quot;Temperature \n anomaly&amp;quot;, low=&amp;quot;Yellow&amp;quot;,high = &amp;quot;red&amp;quot;)+ylab(&amp;quot;Latitude&amp;quot;)+xlab(&amp;quot;Longitude&amp;quot;) + theme_bw()

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2013-07-19-rWBclimate-maps/wtempMap.png&#34; alt=&#34;center&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This creates a world map of temperature anomalies. There&amp;rsquo;s a tremendous amount of data available that you can map and and plot available from the climate data api, check out the &lt;a href=&#34;https://github.com/ropensci/rWBclimate/blob/master/README.md&#34;&gt;vignette up on the github webpage for a full tutorial.&lt;/a&gt;&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
