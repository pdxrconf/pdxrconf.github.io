<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Databases on rOpenSci - open tools for open science</title>
    <link>https://ropensci.org/tags/databases/</link>
    <description>Recent content in Databases on rOpenSci - open tools for open science</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 08 Nov 2017 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://ropensci.org/tags/databases/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>solrium 1.0: Working with Solr from R</title>
      <link>https://ropensci.org/technotes/2017/11/08/solrium-solr-r/</link>
      <pubDate>Wed, 08 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/technotes/2017/11/08/solrium-solr-r/</guid>
      <description>
        
        

&lt;p&gt;Nearly 4 years ago I wrote on this blog about an R package &lt;a href=&#34;https://github.com/ropensci/solr&#34;&gt;solr&lt;/a&gt; for working with the database &lt;a href=&#34;https://lucene.apache.org/solr/&#34;&gt;Solr&lt;/a&gt;. Since then we&amp;rsquo;ve created a refresh of that package in the &lt;a href=&#34;https://github.com/ropensci/solrium&#34;&gt;solrium&lt;/a&gt; package. Since &lt;code&gt;solrium&lt;/code&gt; first hit CRAN about two years ago, users have raised a number of issues that required breaking changes. Thus, this blog post is about a major version bump in &lt;code&gt;solrium&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;what-is-solr&#34;&gt;What is Solr?&lt;/h2&gt;

&lt;p&gt;Solr is a &amp;ldquo;search platform&amp;rdquo; - a NoSQL database - data is organized by so called documents that are xml/json/etc blobs of text. Documents are nested within either collections or cores (depending on the mode you start Solr in). Solr makes it easy to search for documents, with a huge variety of parameters, and a number of different data formats (json/xml/csv). Solr is similar to &lt;a href=&#34;https://www.elastic.co/products/elasticsearch&#34;&gt;Elasticsearch&lt;/a&gt; (see our Elasticsearch client &lt;a href=&#34;https://github.com/ropensci/elastic&#34;&gt;elastic&lt;/a&gt;) - and was around before it. Solr in my opinion is harder to setup than Elasticsearch, but I don&amp;rsquo;t claim to be an expert on either.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;vignettes&#34;&gt;Vignettes&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cran.rstudio.com/web/packages/solrium/vignettes/search.html&#34;&gt;Solr Search with solrium&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cran.rstudio.com/web/packages/solrium/vignettes/local_setup.html&#34;&gt;Local Solr setup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cran.rstudio.com/web/packages/solrium/vignettes/document_management.html&#34;&gt;Document management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cran.rstudio.com/web/packages/solrium/vignettes/cores_collections.html&#34;&gt;Cores/collections management&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;noteable-features&#34;&gt;Noteable features&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Added in v1, you can now work with many connection objects to different Solr instances.&lt;/li&gt;
&lt;li&gt;Methods for the major search functionalities: search, highlight, stats, mlt, group, and facet. In addition, a catch all function &lt;code&gt;all&lt;/code&gt; to combine all of those.&lt;/li&gt;
&lt;li&gt;Comprehensive coverage of the Solr HTTP API&lt;/li&gt;
&lt;li&gt;Can coerce data from Solr API into data.frame&amp;rsquo;s when possible&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;setup&#34;&gt;Setup&lt;/h2&gt;

&lt;p&gt;Install &lt;code&gt;solrium&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;solrium&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or get the development version:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;devtools::install_github(&amp;quot;ropensci/solrium&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(solrium)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;initialize-a-client&#34;&gt;Initialize a client&lt;/h2&gt;

&lt;p&gt;A big change in &lt;code&gt;v1&lt;/code&gt; of &lt;code&gt;solrium&lt;/code&gt; is &lt;code&gt;solr_connect&lt;/code&gt; has been replaced by &lt;code&gt;SolrClient&lt;/code&gt;. Now you create an &lt;code&gt;R6&lt;/code&gt; connection object with &lt;code&gt;SolrClient&lt;/code&gt;, then you can call methods on that &lt;code&gt;R6&lt;/code&gt; object, &lt;strong&gt;OR&lt;/strong&gt; you can pass the connection object to functions.&lt;/p&gt;

&lt;p&gt;By default, &lt;code&gt;SolrClient$new()&lt;/code&gt; sets connections details for a Solr instance that&amp;rsquo;s running on &lt;code&gt;localhost&lt;/code&gt;, and on port &lt;code&gt;8983&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;(conn &amp;lt;- SolrClient$new())
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;#&amp;gt; &amp;lt;Solr Client&amp;gt;
#&amp;gt;   host: 127.0.0.1
#&amp;gt;   path: 
#&amp;gt;   port: 8983
#&amp;gt;   scheme: http
#&amp;gt;   errors: simple
#&amp;gt;   proxy:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;On instantiation, it does not check that the Solr instance is up, but merely sets connection details. You can check if the instance is up by doing for example (assuming you have a collection named &lt;code&gt;gettingstarted&lt;/code&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;conn$ping(&amp;quot;gettingstarted&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;#&amp;gt; $responseHeader
#&amp;gt; $responseHeader$zkConnected
#&amp;gt; [1] TRUE
#&amp;gt; 
#&amp;gt; $responseHeader$status
#&amp;gt; [1] 0
#&amp;gt; 
#&amp;gt; $responseHeader$QTime
#&amp;gt; [1] 163
#&amp;gt; 
#&amp;gt; $responseHeader$params
#&amp;gt; $responseHeader$params$q
#&amp;gt; [1] &amp;quot;{!lucene}*:*&amp;quot;
#&amp;gt; 
#&amp;gt; $responseHeader$params$distrib
#&amp;gt; [1] &amp;quot;false&amp;quot;
#&amp;gt; 
#&amp;gt; $responseHeader$params$df
#&amp;gt; [1] &amp;quot;_text_&amp;quot;
#&amp;gt; 
#&amp;gt; $responseHeader$params$rows
#&amp;gt; [1] &amp;quot;10&amp;quot;
#&amp;gt; 
#&amp;gt; $responseHeader$params$wt
#&amp;gt; [1] &amp;quot;json&amp;quot;
#&amp;gt; 
#&amp;gt; $responseHeader$params$echoParams
#&amp;gt; [1] &amp;quot;all&amp;quot;
#&amp;gt; 
#&amp;gt; 
#&amp;gt; 
#&amp;gt; $status
#&amp;gt; [1] &amp;quot;OK&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A good hint when connecting to a publicly exposed Solr instance is that you likely don&amp;rsquo;t need to specify a port, so a pattern like this should work to connect to a URL like &lt;code&gt;http://foobar.com/search&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;SolrClient$new(host = &amp;quot;foobar.com&amp;quot;, path = &amp;quot;search&amp;quot;, port = NULL)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If the instance uses SSL, simply specify that like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;SolrClient$new(host = &amp;quot;foobar.com&amp;quot;, path = &amp;quot;search&amp;quot;, port = NULL, scheme = &amp;quot;https&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;query-and-body-parameters&#34;&gt;Query and body parameters&lt;/h2&gt;

&lt;p&gt;Another big change in the package is that we wanted to make it easy to determine whether your Solr query gets passed as query parameters in a &lt;code&gt;GET&lt;/code&gt; request or as body in a &lt;code&gt;POST&lt;/code&gt; request. Solr clients in some other languages do this, and it made sense to port over that idea here. Now you pass your key-value pairs to either &lt;code&gt;params&lt;/code&gt; or &lt;code&gt;body&lt;/code&gt;. If nothing is passed to &lt;code&gt;body&lt;/code&gt;, we do a &lt;code&gt;GET&lt;/code&gt; request. If something is passed to &lt;code&gt;body&lt;/code&gt; we do a &lt;code&gt;POST&lt;/code&gt; request, even if there&amp;rsquo;s also key-value pairs passed to &lt;code&gt;params&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;This change does break the interface we had in the old version, but we think it&amp;rsquo;s worth it.&lt;/p&gt;

&lt;p&gt;For example, to do a search you have to pass the collection name and a list of named parameters:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;conn$search(name = &amp;quot;gettingstarted&amp;quot;, params = list(q = &amp;quot;*:*&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;#&amp;gt; # A tibble: 5 x 5
#&amp;gt;      id   title title_str  `_version_` price
#&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
#&amp;gt; 1    10 adfadsf   adfadsf 1.582913e+18    NA
#&amp;gt; 2    12  though    though 1.582913e+18    NA
#&amp;gt; 3    14 animals   animals 1.582913e+18    NA
#&amp;gt; 4     1    &amp;lt;NA&amp;gt;      &amp;lt;NA&amp;gt; 1.582913e+18   100
#&amp;gt; 5     2    &amp;lt;NA&amp;gt;      &amp;lt;NA&amp;gt; 1.582913e+18   500
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can instead pass the connection object to &lt;code&gt;solr_search&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;solr_search(conn, name = &amp;quot;gettingstarted&amp;quot;, params = list(q = &amp;quot;*:*&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;#&amp;gt; # A tibble: 5 x 5
#&amp;gt;      id   title title_str  `_version_` price
#&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
#&amp;gt; 1    10 adfadsf   adfadsf 1.582913e+18    NA
#&amp;gt; 2    12  though    though 1.582913e+18    NA
#&amp;gt; 3    14 animals   animals 1.582913e+18    NA
#&amp;gt; 4     1    &amp;lt;NA&amp;gt;      &amp;lt;NA&amp;gt; 1.582913e+18   100
#&amp;gt; 5     2    &amp;lt;NA&amp;gt;      &amp;lt;NA&amp;gt; 1.582913e+18   500
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And the same pattern applies for the other functions:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;solr_facet&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;solr_group&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;solr_mlt&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;solr_highlight&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;solr_stats&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;solr_all&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;new-functions-for-atomic-updates&#34;&gt;New functions for atomic updates&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ropensci/solrium/issues/97&#34;&gt;A user requested&lt;/a&gt; the ability to do &lt;a href=&#34;https://lucene.apache.org/solr/guide/7_0/updating-parts-of-documents.html&#34;&gt;atomic updates&lt;/a&gt; - partial updates to documents without having to re-index the entire document.&lt;/p&gt;

&lt;p&gt;Two functions were added: &lt;code&gt;update_atomic_json&lt;/code&gt; and &lt;code&gt;update_atomic_xml&lt;/code&gt; for JSON and XML based updates. Check out their help pages for usage.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;search-results-as-attributes&#34;&gt;Search results as attributes&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;solr_search&lt;/code&gt; and &lt;code&gt;solr_all&lt;/code&gt; in &lt;code&gt;v1&lt;/code&gt; gain attributes that include &lt;code&gt;numFound&lt;/code&gt;, &lt;code&gt;start&lt;/code&gt;, and &lt;code&gt;maxScore&lt;/code&gt;. That is, you can get to these three values after data is returned. Note that some Solr instances may not return all three values.&lt;/p&gt;

&lt;p&gt;For example, let&amp;rsquo;s use the Public Library of Science Solr search instance at &lt;a href=&#34;http://api.plos.org/search&#34;&gt;http://api.plos.org/search&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plos &amp;lt;- SolrClient$new(host = &amp;quot;api.plos.org&amp;quot;, path = &amp;quot;search&amp;quot;, port = NULL)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Search&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res &amp;lt;- plos$search(params = list(q = &amp;quot;*:*&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Get attributes&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;attr(res, &amp;quot;numFound&amp;quot;)
#&amp;gt; [1] 1902279
attr(res, &amp;quot;start&amp;quot;)
#&amp;gt; [1] 0
attr(res, &amp;quot;maxScore&amp;quot;)
#&amp;gt; [1] 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;automatically-adjust-rows-parameter&#34;&gt;Automatically adjust rows parameter&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ropensci/solrium/pull/102&#34;&gt;A user higlighted&lt;/a&gt; that &lt;a href=&#34;https://wiki.apache.org/solr/SolrPerformanceProblems#Asking_for_too_many_rows&#34;&gt;there&amp;rsquo;s a performance penalty when asking for too many rows&lt;/a&gt;. The resulting change in &lt;code&gt;solrium&lt;/code&gt; is that in some search functions we automatically adjust the &lt;code&gt;rows&lt;/code&gt; parameter to avoid the performance penalty.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;usage-in-other-packages&#34;&gt;Usage in other packages&lt;/h2&gt;

&lt;p&gt;I maintain 4 other packages that use &lt;code&gt;solrium&lt;/code&gt;: &lt;a href=&#34;https://github.com/ropensci/rplos&#34;&gt;rplos&lt;/a&gt;, &lt;a href=&#34;https://github.com/ropensci/ritis&#34;&gt;ritis&lt;/a&gt;, &lt;a href=&#34;https://github.com/ropensci/rdatacite&#34;&gt;rdatacite&lt;/a&gt;, and &lt;a href=&#34;https://github.com/ropensci/rdryad&#34;&gt;rdryad&lt;/a&gt;. If you are interested in using &lt;code&gt;solrium&lt;/code&gt; in your package, looking at any of those four packages will give a good sense of how to do it.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;notes&#34;&gt;Notes&lt;/h2&gt;

&lt;h3 id=&#34;solr-pkg&#34;&gt;solr pkg&lt;/h3&gt;

&lt;p&gt;The &lt;code&gt;solr&lt;/code&gt; package will soon be archived on CRAN. We&amp;rsquo;ve moved all packages depending on it to &lt;code&gt;solrium&lt;/code&gt;. Let me know ASAP if you have any complaints about archiving it on CRAN.&lt;/p&gt;

&lt;h3 id=&#34;feedback&#34;&gt;Feedback!&lt;/h3&gt;

&lt;p&gt;Please do upgrade/install &lt;code&gt;solrium&lt;/code&gt;  &lt;code&gt;v1&lt;/code&gt; and let us know what you think.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>elastic - Elasticsearch for R</title>
      <link>https://ropensci.org/technotes/2017/08/02/elasticsearch-client/</link>
      <pubDate>Wed, 02 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/technotes/2017/08/02/elasticsearch-client/</guid>
      <description>
        
        

&lt;p&gt;&lt;strong&gt;elastic&lt;/strong&gt; is an R client for &lt;a href=&#34;https://www.elastic.co/products/elasticsearch&#34;&gt;Elasticsearch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;elastic&lt;/code&gt; has been around since 2013, with the first commit in &lt;a href=&#34;https://github.com/ropensci/elastic/commit/f7b04589b2cb711a21223bb4f20b34bc9330ef8d&#34;&gt;November, 2013&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;sidebar - &amp;lsquo;elastic&amp;rsquo; was picked as a package named before the company now known as Elastic
changed their name to Elastic.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;what-is-elasticsearch&#34;&gt;What is Elasticsearch?&lt;/h3&gt;

&lt;p&gt;If you aren&amp;rsquo;t familiar with Elasticsearch, it is a distributed, RESTful search and analytics engine.
It&amp;rsquo;s similar to &lt;a href=&#34;https://lucene.apache.org/solr/&#34;&gt;Solr&lt;/a&gt;. It falls in the NoSQL bin of databases, holding data in JSON documents, instead
of rows and columns. Elasticsearch has a concept of &lt;strong&gt;index&lt;/strong&gt;, similar to a database in SQL-land.
You can hold many documents of similar type within a single index. There is powerful search
capabilities, including lots of different types of queries that can be done separately
or combined. And best of all it&amp;rsquo;s super fast.&lt;/p&gt;

&lt;h3 id=&#34;other-clients&#34;&gt;Other clients&lt;/h3&gt;

&lt;p&gt;The Elastic company maintains some official clients, including the Python client
&lt;a href=&#34;http://elasticsearch-py.readthedocs.io/en/master/&#34;&gt;elasticsearch-py&lt;/a&gt;, and it&amp;rsquo;s higher
level DSL client &lt;a href=&#34;https://elasticsearch-dsl.readthedocs.io/en/latest/&#34;&gt;elasticsearch-dsl&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I won&amp;rsquo;t talk much about it, but we have slowly been working on an R equivalent of the
Python DSL client, called &lt;a href=&#34;https://github.com/ropensci/elasticdsl&#34;&gt;elasticdsl&lt;/a&gt;, for
a human friendly way to compose Elasticsearch queries.&lt;/p&gt;

&lt;h3 id=&#34;vignettes&#34;&gt;Vignettes&lt;/h3&gt;

&lt;p&gt;Check out the &lt;a href=&#34;https://cran.rstudio.com/web/packages/elastic/vignettes/elastic_intro.html&#34;&gt;elastic introduction vignette&lt;/a&gt;
and the &lt;a href=&#34;https://cran.rstudio.com/web/packages/elastic/vignettes/search.html&#34;&gt;search vignette&lt;/a&gt; to get started.&lt;/p&gt;

&lt;h3 id=&#34;noteable-features&#34;&gt;Noteable features&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;elastic&lt;/code&gt; has nearly complete coverage of the Elasticsearch HTTP API. If there&amp;rsquo;s
anything missing you need in this client, let us know! Check out the
&lt;a href=&#34;https://github.com/ropensci/elastic/issues?q=is%3Aissue+is%3Aopen+label%3Afeatures&#34;&gt;features label&lt;/a&gt;
for features we plan to add to the package.&lt;/li&gt;
&lt;li&gt;We fail well. This is important to us. We allow the user to choose simple errors
to just give e.g., 404 HTTP error, or complex errors, including full stack trace
from Elasticsearch in addition to the HTTP errror. We strive to fail well when
users give the wrong type of input, etc. as well. Let us know if &lt;code&gt;elastic&lt;/code&gt; is not
failing well!&lt;/li&gt;
&lt;li&gt;We strive to allow R centric ways of interacting with Elasticsearch. For example,
in the function &lt;code&gt;docs_bulk&lt;/code&gt;, our interface to the Elasticsearch &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html&#34;&gt;bulk API&lt;/a&gt;
we make it easy to create documents in your Elasticsearch instance from R lists,
data.frame&amp;rsquo;s and from bulk format files on disk.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;elastic&lt;/code&gt; works with most versions of Elasticsearch. We run the test suite on 11
versions of Elasticsearch, from &lt;code&gt;v1.0.0&lt;/code&gt; up to &lt;code&gt;v5.5.0&lt;/code&gt;. We strive to fail well
with useful messages when there is a feature no longer available or one that is
a new feature and not available in previous Elasticsearch versions.&lt;/li&gt;
&lt;li&gt;Search inputs are flexible: lists and JSON strings both work.&lt;/li&gt;
&lt;li&gt;Arguably, a noteable feature is that this client has been around nearly 4 years,
so we&amp;rsquo;ve surfaced and squashed many bugs.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;getting-help&#34;&gt;Getting help&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;If you have a bug or a feature request, post it in the repo at &lt;a href=&#34;https://github.com/ropensci/elastic/issues&#34;&gt;https://github.com/ropensci/elastic/issues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Stackoverflow: Check out combination of the tags &lt;code&gt;[elasticsearch]&lt;/code&gt; and &lt;code&gt;[r]&lt;/code&gt; &lt;a href=&#34;https://stackoverflow.com/questions/tagged/elasticsearch+r&#34;&gt;https://stackoverflow.com/questions/tagged/elasticsearch+r&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Reach out to me on Twitter at &lt;a href=&#34;https://twitter.com/sckottie&#34;&gt;@sckottie&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Post question/problem in the &lt;a href=&#34;https://discuss.ropensci.org/&#34;&gt;rOpenSci discussion forum&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Email me &lt;a href=&#34;mailto:myrmecocystus@gmail.com&#34;&gt;directly&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;setup&#34;&gt;Setup&lt;/h3&gt;

&lt;p&gt;Install &lt;code&gt;elastic&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;elastic&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or get the development version:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;devtools::install_github(&amp;quot;ropensci/elastic&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(elastic)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I&amp;rsquo;m running Elasticsearch version:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ping()$version$number
#&amp;gt; [1] &amp;quot;5.4.0&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;

&lt;h4 id=&#34;initialize-a-client&#34;&gt;Initialize a client&lt;/h4&gt;

&lt;p&gt;Using &lt;code&gt;connect()&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;elastic::connect()
#&amp;gt; transport:  http
#&amp;gt; host:       127.0.0.1
#&amp;gt; port:       9200
#&amp;gt; path:       NULL
#&amp;gt; username:   NULL
#&amp;gt; password:   &amp;lt;secret&amp;gt;
#&amp;gt; errors:     simple
#&amp;gt; headers (names):  NULL
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By default, you connect to &lt;code&gt;localhost&lt;/code&gt; and port &lt;code&gt;9200&lt;/code&gt;. There&amp;rsquo;s paramaters
for setting transport schema, username, password, and base search path (e.g.,
&lt;code&gt;_search&lt;/code&gt; or something else).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;See bottom of post about possible changes in connections.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;get-some-data&#34;&gt;Get some data&lt;/h4&gt;

&lt;p&gt;Elasticsearch has a bulk load API to load data in fast. The format is pretty weird
though. It&amp;rsquo;s sort of JSON, but would pass no JSON linter. I include a few data
sets in &lt;code&gt;elastic&lt;/code&gt; so it&amp;rsquo;s easy to get up and running, and so when you run examples
in this package they&amp;rsquo;ll actually run the same way (hopefully).&lt;/p&gt;

&lt;h4 id=&#34;public-library-of-science-plos-data&#34;&gt;Public Library of Science (PLOS) data&lt;/h4&gt;

&lt;p&gt;A dataset inluded in the &lt;code&gt;elastic&lt;/code&gt; package is metadata for PLOS scholarly articles.
Get the file path, then load:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plosdat &amp;lt;- system.file(&amp;quot;examples&amp;quot;, &amp;quot;plos_data.json&amp;quot;, package = &amp;quot;elastic&amp;quot;)
invisible(docs_bulk(plosdat))
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;search&#34;&gt;Search&lt;/h4&gt;

&lt;p&gt;The main search function is &lt;code&gt;Search()&lt;/code&gt;. Running it without any inputs searches
across all indices - in this case only the &lt;code&gt;plos&lt;/code&gt; index.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Search()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;#&amp;gt; $took
#&amp;gt; [1] 1
#&amp;gt;
#&amp;gt; $timed_out
#&amp;gt; [1] FALSE
#&amp;gt;
#&amp;gt; $`_shards`
#&amp;gt; $`_shards`$total
#&amp;gt; [1] 5
#&amp;gt;
#&amp;gt; $`_shards`$successful
#&amp;gt; [1] 5
#&amp;gt;
#&amp;gt; $`_shards`$failed
#&amp;gt; [1] 0
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Search just the &lt;code&gt;plos&lt;/code&gt; index and only return 1 result&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Search(index = &amp;quot;plos&amp;quot;, size = 1)$hits$hits
#&amp;gt; [[1]]
#&amp;gt; [[1]]$`_index`
#&amp;gt; [1] &amp;quot;plos&amp;quot;
#&amp;gt;
#&amp;gt; [[1]]$`_type`
#&amp;gt; [1] &amp;quot;article&amp;quot;
#&amp;gt;
#&amp;gt; [[1]]$`_id`
#&amp;gt; [1] &amp;quot;0&amp;quot;
#&amp;gt;
#&amp;gt; [[1]]$`_score`
#&amp;gt; [1] 1
#&amp;gt;
#&amp;gt; [[1]]$`_source`
#&amp;gt; [[1]]$`_source`$id
#&amp;gt; [1] &amp;quot;10.1371/journal.pone.0007737&amp;quot;
#&amp;gt;
#&amp;gt; [[1]]$`_source`$title
#&amp;gt; [1] &amp;quot;Phospholipase C-Î²4 Is Essential for the Progression of the Normal Sleep Sequence and Ultradian Body Temperature Rhythms in Mice&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Search the &lt;code&gt;plos&lt;/code&gt; index, and the &lt;code&gt;article&lt;/code&gt; document type, sort by title, and query for &lt;em&gt;antibody&lt;/em&gt;, limit to 1 result.&lt;/p&gt;

&lt;p&gt;First, with Elasticsearch &lt;code&gt;v5&lt;/code&gt; and greater, we need to set &lt;code&gt;fielddata = true&lt;/code&gt; if we want to search on or sort on a text field.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mapping_create(&amp;quot;plos&amp;quot;, &amp;quot;article&amp;quot;, update_all_types = TRUE, body = &#39;{
   &amp;quot;properties&amp;quot;: {
     &amp;quot;title&amp;quot;: {
     &amp;quot;type&amp;quot;:     &amp;quot;text&amp;quot;,
     &amp;quot;fielddata&amp;quot;: true
   }
 }
}&#39;)
#&amp;gt; $acknowledged
#&amp;gt; [1] TRUE
Search(index = &amp;quot;plos&amp;quot;, type = &amp;quot;article&amp;quot;, sort = &amp;quot;title&amp;quot;, q = &amp;quot;antibody&amp;quot;, size = 1)$hits$hits
#&amp;gt; [[1]]
#&amp;gt; [[1]]$`_index`
#&amp;gt; [1] &amp;quot;plos&amp;quot;
#&amp;gt;
#&amp;gt; [[1]]$`_type`
#&amp;gt; [1] &amp;quot;article&amp;quot;
#&amp;gt;
#&amp;gt; [[1]]$`_id`
#&amp;gt; [1] &amp;quot;568&amp;quot;
#&amp;gt;
#&amp;gt; [[1]]$`_score`
#&amp;gt; NULL
#&amp;gt;
#&amp;gt; [[1]]$`_source`
#&amp;gt; [[1]]$`_source`$id
#&amp;gt; [1] &amp;quot;10.1371/journal.pone.0085002&amp;quot;
#&amp;gt;
#&amp;gt; [[1]]$`_source`$title
#&amp;gt; [1] &amp;quot;Evaluation of 131I-Anti-Angiotensin II Type 1 Receptor Monoclonal Antibody as a Reporter for Hepatocellular Carcinoma&amp;quot;
#&amp;gt;
#&amp;gt;
#&amp;gt; [[1]]$sort
#&amp;gt; [[1]]$sort[[1]]
#&amp;gt; [1] &amp;quot;1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;get-documents&#34;&gt;Get documents&lt;/h4&gt;

&lt;p&gt;Get document with &lt;code&gt;id=1&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;docs_get(index = &#39;plos&#39;, type = &#39;article&#39;, id = 1)
#&amp;gt; $`_index`
#&amp;gt; [1] &amp;quot;plos&amp;quot;
#&amp;gt;
#&amp;gt; $`_type`
#&amp;gt; [1] &amp;quot;article&amp;quot;
#&amp;gt;
#&amp;gt; $`_id`
#&amp;gt; [1] &amp;quot;1&amp;quot;
#&amp;gt;
#&amp;gt; $`_version`
#&amp;gt; [1] 1
#&amp;gt;
#&amp;gt; $found
#&amp;gt; [1] TRUE
#&amp;gt;
#&amp;gt; $`_source`
#&amp;gt; $`_source`$id
#&amp;gt; [1] &amp;quot;10.1371/journal.pone.0098602&amp;quot;
#&amp;gt;
#&amp;gt; $`_source`$title
#&amp;gt; [1] &amp;quot;Population Genetic Structure of a Sandstone Specialist and a Generalist Heath Species at Two Levels of Sandstone Patchiness across the Strait of Gibraltar&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Get certain fields&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;docs_get(index = &#39;plos&#39;, type = &#39;article&#39;, id = 1, fields = &#39;id&#39;)
#&amp;gt; $`_index`
#&amp;gt; [1] &amp;quot;plos&amp;quot;
#&amp;gt;
#&amp;gt; $`_type`
#&amp;gt; [1] &amp;quot;article&amp;quot;
#&amp;gt;
#&amp;gt; $`_id`
#&amp;gt; [1] &amp;quot;1&amp;quot;
#&amp;gt;
#&amp;gt; $`_version`
#&amp;gt; [1] 1
#&amp;gt;
#&amp;gt; $found
#&amp;gt; [1] TRUE
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;raw-json-data&#34;&gt;Raw JSON data&lt;/h4&gt;

&lt;p&gt;You can optionally get back raw JSON from many functions by setting parameter &lt;code&gt;raw=TRUE&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;For example, get raw JSON, then parse with &lt;code&gt;jsonlite&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;(out &amp;lt;- docs_mget(index = &amp;quot;plos&amp;quot;, type = &amp;quot;article&amp;quot;, id = 5:6, raw = TRUE))
#&amp;gt; [1] &amp;quot;{\&amp;quot;docs\&amp;quot;:[{\&amp;quot;_index\&amp;quot;:\&amp;quot;plos\&amp;quot;,\&amp;quot;_type\&amp;quot;:\&amp;quot;article\&amp;quot;,\&amp;quot;_id\&amp;quot;:\&amp;quot;5\&amp;quot;,\&amp;quot;_version\&amp;quot;:1,\&amp;quot;found\&amp;quot;:true,\&amp;quot;_source\&amp;quot;:{\&amp;quot;id\&amp;quot;:\&amp;quot;10.1371/journal.pone.0085123\&amp;quot;,\&amp;quot;title\&amp;quot;:\&amp;quot;MiR-21 Is under Control of STAT5 but Is Dispensable for Mammary Development and Lactation\&amp;quot;}},{\&amp;quot;_index\&amp;quot;:\&amp;quot;plos\&amp;quot;,\&amp;quot;_type\&amp;quot;:\&amp;quot;article\&amp;quot;,\&amp;quot;_id\&amp;quot;:\&amp;quot;6\&amp;quot;,\&amp;quot;_version\&amp;quot;:1,\&amp;quot;found\&amp;quot;:true,\&amp;quot;_source\&amp;quot;:{\&amp;quot;id\&amp;quot;:\&amp;quot;10.1371/journal.pone.0098600\&amp;quot;,\&amp;quot;title\&amp;quot;:\&amp;quot;Correction: Designing Mixed Species Tree Plantations for the Tropics: Balancing Ecological Attributes of Species with Landholder Preferences in the Philippines\&amp;quot;}}]}&amp;quot;
#&amp;gt; attr(,&amp;quot;class&amp;quot;)
#&amp;gt; [1] &amp;quot;elastic_mget&amp;quot;
jsonlite::fromJSON(out)
#&amp;gt; $docs
#&amp;gt;   _index   _type _id _version found                   _source.id
#&amp;gt; 1   plos article   5        1  TRUE 10.1371/journal.pone.0085123
#&amp;gt; 2   plos article   6        1  TRUE 10.1371/journal.pone.0098600
#&amp;gt;                                                                                                                                                     _source.title
#&amp;gt; 1                                                                       MiR-21 Is under Control of STAT5 but Is Dispensable for Mammary Development and Lactation
#&amp;gt; 2 Correction: Designing Mixed Species Tree Plantations for the Tropics: Balancing Ecological Attributes of Species with Landholder Preferences in the Philippines
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;aggregation-search&#34;&gt;Aggregation search&lt;/h4&gt;

&lt;p&gt;Here, we&amp;rsquo;ll use another dataset that comes with the package on Shakespeare plays.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;gbifdat &amp;lt;- system.file(&amp;quot;examples&amp;quot;, &amp;quot;gbif_data.json&amp;quot;, package = &amp;quot;elastic&amp;quot;)
invisible(docs_bulk(gbifdat))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Define an aggregation query:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;aggs &amp;lt;- &#39;{
    &amp;quot;aggs&amp;quot;: {
        &amp;quot;latbuckets&amp;quot; : {
           &amp;quot;histogram&amp;quot; : {
               &amp;quot;field&amp;quot; : &amp;quot;decimalLatitude&amp;quot;,
               &amp;quot;interval&amp;quot; : 5
           }
        }
    }
}&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Search the &lt;code&gt;gbif&lt;/code&gt; index&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res &amp;lt;- Search(index = &amp;quot;gbif&amp;quot;, body = aggs, size = 0)$aggregations$latbuckets$buckets
do.call(&amp;quot;rbind.data.frame&amp;quot;, res)
#&amp;gt;    key doc_count
#&amp;gt; 2  -35         1
#&amp;gt; 22 -30         0
#&amp;gt; 3  -25         0
#&amp;gt; 4  -20         0
#&amp;gt; 5  -15         0
#&amp;gt; 6  -10         0
#&amp;gt; 7   -5         1
#&amp;gt; 8    0         0
#&amp;gt; 9    5         0
#&amp;gt; 10  10         0
#&amp;gt; 11  15         0
#&amp;gt; 12  20         0
#&amp;gt; 13  25         4
#&amp;gt; 14  30         2
#&amp;gt; 15  35         3
#&amp;gt; 16  40         2
#&amp;gt; 17  45        66
#&amp;gt; 18  50       183
#&amp;gt; 19  55       487
#&amp;gt; 20  60       130
#&amp;gt; 21  65        20
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;scrolling-search-instead-of-paging&#34;&gt;Scrolling search - instead of paging&lt;/h4&gt;

&lt;p&gt;When you want all the documents, your best bet is likely to be &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-scroll.html&#34;&gt;scrolling search&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s an example. First, use &lt;code&gt;Search()&lt;/code&gt;, setting a value for the &lt;code&gt;scroll&lt;/code&gt; parameter.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res1 &amp;lt;- Search(index = &#39;shakespeare&#39;, scroll = &amp;quot;1m&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You get a scroll ID back when setting the &lt;code&gt;scroll&lt;/code&gt; parameter&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res1$`_scroll_id`
#&amp;gt; [1] &amp;quot;DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAElFnZ2X3FJVWEyUU1HQjl2cFpWUFl0cXcAAAAAAAABJBZ2dl9xSVVhMlFNR0I5dnBaVlBZdHF3AAAAAAAAAScWdnZfcUlVYTJRTUdCOXZwWlZQWXRxdwAAAAAAAAEmFnZ2X3FJVWEyUU1HQjl2cFpWUFl0cXcAAAAAAAABIxZ2dl9xSVVhMlFNR0I5dnBaVlBZdHF3&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Use a while loop to get all results&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;out1 &amp;lt;- list()
hits &amp;lt;- 1
while (hits != 0) {
  tmp1 &amp;lt;- scroll(scroll_id = res1$`_scroll_id`)
  hits &amp;lt;- length(tmp1$hits$hits)
  if (hits &amp;gt; 0) {
   out1 &amp;lt;- c(out1, tmp1$hits$hits)
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Woohoo! Collected all 1 documents in very little time.&lt;/p&gt;

&lt;p&gt;Now, get &lt;code&gt;_source&lt;/code&gt; from each document:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;docs &amp;lt;- lapply(out1, &amp;quot;[[&amp;quot;, &amp;quot;_source&amp;quot;)
length(docs)
#&amp;gt; [1] 4988
vapply(docs[1:10], &amp;quot;[[&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;text_entry&amp;quot;)
#&amp;gt;  [1] &amp;quot;Without much shame retold or spoken of.&amp;quot;
#&amp;gt;  [2] &amp;quot;For more uneven and unwelcome news&amp;quot;
#&amp;gt;  [3] &amp;quot;And shape of likelihood, the news was told;&amp;quot;
#&amp;gt;  [4] &amp;quot;Mordake the Earl of Fife, and eldest son&amp;quot;
#&amp;gt;  [5] &amp;quot;It is a conquest for a prince to boast of.&amp;quot;
#&amp;gt;  [6] &amp;quot;Amongst a grove, the very straightest plant;&amp;quot;
#&amp;gt;  [7] &amp;quot;That some night-tripping fairy had exchanged&amp;quot;
#&amp;gt;  [8] &amp;quot;Then would I have his Harry, and he mine.&amp;quot;
#&amp;gt;  [9] &amp;quot;This is his uncles teaching; this is Worcester,&amp;quot;
#&amp;gt; [10] &amp;quot;Malevolent to you in all aspects;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;bulk-documents&#34;&gt;Bulk documents&lt;/h4&gt;

&lt;p&gt;You&amp;rsquo;ve already seen the bulk docs API in action above. Above though, we were
using &lt;code&gt;docs_bulk.character&lt;/code&gt; - where the input is a character string that&amp;rsquo;s a
file path.&lt;/p&gt;

&lt;p&gt;Here, I&amp;rsquo;ll describe briefly how you can insert any data.frame as documents in your
Elasticsearch instance. We&amp;rsquo;ll use the diamonds dataset from the ~54K row &lt;code&gt;ggplot2&lt;/code&gt;
package.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#&amp;gt; $acknowledged
#&amp;gt; [1] TRUE
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(ggplot2)
invisible(docs_bulk(diamonds, &amp;quot;diam&amp;quot;))
#&amp;gt; |==================================| 100%
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Search(&amp;quot;diam&amp;quot;)$hits$total
#&amp;gt; [1] 47375
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That&amp;rsquo;s pretty easy! This function is used a lot, particularly with data.frame&amp;rsquo;s - so
we get many questions/feedback on this so it will just keep getting better/faster.&lt;/p&gt;

&lt;h3 id=&#34;to-do&#34;&gt;TO DO&lt;/h3&gt;

&lt;h4 id=&#34;connections&#34;&gt;Connections&lt;/h4&gt;

&lt;p&gt;We&amp;rsquo;re planning to roll out changes in how you connect to Elasticsearch from &lt;code&gt;elastic&lt;/code&gt;.
Right now, you can only connect to one Elasticsearch instance per R session -
your details are set and then recalled internally in each function. We plan to change
this to instantiate a client and then you either call functions on the client
(e.g., using &lt;code&gt;R6&lt;/code&gt;) or pass the client object onto functions.&lt;/p&gt;

&lt;p&gt;Checkout &lt;a href=&#34;https://github.com/ropensci/elastic/issues/87&#34;&gt;issue #87&lt;/a&gt; to follow
progress or discuss.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h4 id=&#34;move-to-using-crul-for-http&#34;&gt;Move to using crul for http&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;crul&lt;/code&gt; is a relatively new R http client - and has async baked in - as well as mocking.
Development should be easier with it as I can mock requests for test suites, and
allow users to toggle async more easily.&lt;/p&gt;

&lt;h3 id=&#34;call-to-action&#34;&gt;Call to action&lt;/h3&gt;

&lt;p&gt;We can use your help! Elasticsearch development moves pretty fast - we&amp;rsquo;d love this client to
work with every single Elasticsearch version to the extent possible - and we&amp;rsquo;d love to
squash every bug and solve every feature request fast.&lt;/p&gt;

&lt;p&gt;If you need to use Elasticsearch from R, please try out &lt;code&gt;elastic&lt;/code&gt;!&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Report bugs!&lt;/li&gt;
&lt;li&gt;File feature requests!&lt;/li&gt;
&lt;li&gt;Send PR&amp;rsquo;s!&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Release mongolite 1.0</title>
      <link>https://ropensci.org/blog/2017/03/10/mongolite/</link>
      <pubDate>Fri, 10 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2017/03/10/mongolite/</guid>
      <description>
        
        

&lt;p&gt;After 2.5 years of development, version 1.0 of the &lt;a href=&#34;https://cran.r-project.org/web/packages/mongolite/index.html&#34;&gt;mongolite&lt;/a&gt; package has been released to CRAN. The package is now stable, well documented, and will soon be submitted for peer review to be onboarded in the rOpenSci suite.&lt;/p&gt;

&lt;h2 id=&#34;mongodb-in-r-and-mongolite&#34;&gt;MongoDB in R and mongolite&lt;/h2&gt;

&lt;p&gt;I started working on mongolite in September 2014, and it was first announced at the rOpenSci &lt;a href=&#34;https://twitter.com/_inundata/status/581605601882480640/photo/1&#34;&gt;unconf 2015&lt;/a&gt;. At this time, there were already two Mongo clients on CRAN: &lt;a href=&#34;https://cran.r-project.org/web/packages/rmongodb/index.html&#34;&gt;rmongodb&lt;/a&gt; (no longer works) and &lt;a href=&#34;https://cran.r-project.org/web/packages/RMongo/index.html&#34;&gt;RMongo&lt;/a&gt; (depends on Java). However I found both of them pretty clunky, and the MongoDB folks had just released 1.0 of their new C driver, so I decided to write a new client from scratch.&lt;/p&gt;

&lt;p&gt;Mongolite aims to provide a &lt;em&gt;simple&lt;/em&gt; R client for MongoDB, based on the excellent &lt;a href=&#34;https://github.com/mongodb/mongo-c-driver&#34;&gt;mongo-c-driver&lt;/a&gt; combined with super-powers from the &lt;a href=&#34;https://cran.r-project.org/web/packages/jsonlite/index.html&#34;&gt;jsonlite&lt;/a&gt; package. Simple means insert and query data in R using data-frames with a single command:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Create a connection
con &amp;lt;- mongolite::mongo(&amp;quot;diamonds&amp;quot;,
  url = &amp;quot;mongodb://readwrite:test@ds043942.mongolab.com:43942/jeroen_test&amp;quot;)

# Find diamonds with: cut == Premium &amp;amp; price &amp;lt; 500
mydata &amp;lt;- con$find(&#39;{&amp;quot;cut&amp;quot; : &amp;quot;Premium&amp;quot;, &amp;quot;price&amp;quot; : { &amp;quot;$lt&amp;quot; : 500 } }&#39;)
print(mydata)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Running your own MongoDB server is easy. Either &lt;a href=&#34;https://www.mongodb.com/download-center&#34;&gt;download&lt;/a&gt; it from the website or install it with your favorite package manager. To start the server simply run the &lt;code&gt;mongod&lt;/code&gt; command (d for daemon) in a shell:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Install mongoDB server
brew install mongodb

# Run the server dameon
mongod
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;mongolite::mongo()&lt;/code&gt; function wil default to the localhost server if no URI is specified. Try inserting and reading some data:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Create a connection
con &amp;lt;- mongolite::mongo(&amp;quot;iris&amp;quot;)

# Insert some data
con$insert(datasets::iris)

# Count how much data is in the DB
con$count()

# Read the data back
con$find(&#39;{}&#39;)

# Wipe the collection
con$drop()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In my experience, a simple interface is critical to get started. Obviously, advanced features are available in mongolite as well, but this will get you up to speed right way if you just need the data and get on with your job.&lt;/p&gt;

&lt;h2 id=&#34;bookdown-documentation&#34;&gt;Bookdown documentation&lt;/h2&gt;

&lt;p&gt;The 1.0 release has fresh documentation based on the awesome bookdown system. You can find documentation on the mongolite &lt;a href=&#34;https://jeroen.github.io/mongolite/&#34;&gt;github homepage&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://jeroen.github.io/mongolite/&#34;&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/mongolite-docs.png&#34; alt=&#34;mongolite-docs&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The bookdown is now the primary documentation source for mongolite.&lt;/p&gt;

&lt;h2 id=&#34;why-mongodb&#34;&gt;Why MongoDB&lt;/h2&gt;

&lt;p&gt;MongoDB is the &lt;a href=&#34;(http://db-engines.com/en/ranking)&#34;&gt;most popular&lt;/a&gt; nosql database (by market share), and the 5th most popular database allround. Mongo is relatively young in comparison with the traditional engines (Oracle, Microsoft, MySQL, Postgres), yet well established, fully open source, and backed by a professional company.&lt;/p&gt;

&lt;p&gt;MongoDB provides a modern high-performance DB engine with cool features that cannot be found anywhere else. The high quality client drivers are a pleasure to work with, and actively maintained by professional engineers. Writing bindings, it quickly became obvious that Mongo does not suffer from the legacy bloat that I have come to associate with traditional DB engines.&lt;/p&gt;

&lt;p&gt;At the same time the ecosystem is mature and offers reliability and continuity that makes it stand out from the proliferation of nosql systems. MongoDB has been widely adopted by users and distributions, so I am pretty confident it will still be around 5 or 10 years from now.&lt;/p&gt;

&lt;h2 id=&#34;changes-in-1-0&#34;&gt;Changes in 1.0&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&#34;https://github.com/jeroen/mongolite/blob/master/NEWS&#34;&gt;NEWS&lt;/a&gt; file on Github lists what has changed in this release:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;New mongo bookdown docs at &lt;a href=&#34;https://jeroen.github.io/mongolite&#34;&gt;https://jeroen.github.io/mongolite&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Update mongo-c-driver to upstream 1.6.0&lt;/li&gt;
&lt;li&gt;Add basic decimal 128 support (coerce to double)&lt;/li&gt;
&lt;li&gt;Improve enterprise authentication for LDAP, X509 and Kerberos&lt;/li&gt;
&lt;li&gt;Windows: build with SSPI instead of SASL&lt;/li&gt;
&lt;li&gt;Added &lt;code&gt;allow_invalid_hostname&lt;/code&gt; parameter to &lt;code&gt;ssl_options()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Option &lt;code&gt;bigint_as_char&lt;/code&gt; to parse int64 into string instead of double&lt;/li&gt;
&lt;li&gt;New function &lt;code&gt;mongo_options()&lt;/code&gt; to get/set global options&lt;/li&gt;
&lt;li&gt;Function &lt;code&gt;mongo_log_level()&lt;/code&gt; is removed (use &lt;code&gt;mongo_options()&lt;/code&gt; instead)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;insert()&lt;/code&gt; now substitutes dots in key (column) names with underscores&lt;/li&gt;
&lt;li&gt;Various fixes in &lt;code&gt;update()&lt;/code&gt;, support for upsert&lt;/li&gt;
&lt;li&gt;Add unit tests from bson spec (some tests fail in mongo-c-driver)&lt;/li&gt;
&lt;li&gt;Switch to new C driver API mongoc_collection_find_with_opts()&lt;/li&gt;
&lt;li&gt;Add R_registerRoutines() call to please CMD check&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;tell-us-what-you-think&#34;&gt;Tell us what you think&lt;/h2&gt;

&lt;p&gt;At rOpenSci we&amp;rsquo;re interested to hear who is using R and how. If you decide to give mongolite a try, please share your experiences and suggestions. Open an &lt;a href=&#34;https://github.com/jeroen/mongolite/issues&#34;&gt;issue on github&lt;/a&gt; for specific problems and feature requests, or join the rOpenSci &lt;a href=&#34;https://ropensci.slack.com&#34;&gt;slack&lt;/a&gt; to talk about mongolite or other rOpenSci packages. Or just come say hi and hang out :)&lt;/p&gt;

&lt;p&gt;We both love hearing from academic users, but also industry applications of R and synergy between the industry and open source scientific software.&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
